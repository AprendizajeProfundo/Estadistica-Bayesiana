{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h1 align='center'> Curso de Estadística Bayesiana<br> Introducción</h1> \n",
    "\n",
    "<h3>Autor</h3>\n",
    "\n",
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co\n",
    "2. Daniel Mauricio Montenegro Reyes, dextronomo@gmail.com \n",
    "\n",
    "<h3>Fork</h3>\n",
    "\n",
    "<h3>Referencias</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 1.  Variables aleatorias </h2>\n",
    "\n",
    "\n",
    "Una variable aleatoria (v.a.) $X$ es una función real ${\\displaystyle X:\\Omega \\to \\mathbb {R} }$, definida en el espacio de probabilidad, ${\\displaystyle (\\Omega ,{\\mathcal {A}},P)}$, asociado a un experimento aleatorio. Se puede comprobar que la variable aleatoria $X$ puede ser constante. \n",
    "\n",
    "<h3>Ejemplo de una variable aleatoria discreta</h3> \n",
    "\n",
    "Supóngamos que se lanzan tres monedas sin sesgo (igual probabilidad para cara y para cruz) de manera independiente. Entonces, $P(cara) =0.5$. Denotemos por 1, el resultado cara y por 0 el resultado cruz. El espacio muestral, es decir, el conjunto de posibles resultados es dado por $\\{ (0,0,0), (0,0,1), (0,1,0),(1,0,0), (1,1,0), (1,0,1), (0,1,1), (1,1,1)\\}$,  Ahora definimos la variable aleatoria $X$, como el número de caras que sale. La siguiente tabla muestra los valores posibles de la variable aleatoria.\n",
    "\n",
    "  \n",
    "|obs: $x$|prob: $P(x)$ |var: $X$|\n",
    "|------|------|------|\n",
    "| (0,0,0) | 1/8 | 0  |\n",
    "| (0,0,1) | 1/8 | 1  |\n",
    "| (0,1,0) | 1/8 | 1  |\n",
    "| (1,0,0) | 1/8 | 1  |\n",
    "| (0,1,1) | 1/8 | 2  |\n",
    "| (1,1,0) | 1/8 | 2  |\n",
    "| (1,0,1) | 1/8 | 2  |\n",
    "| (1,1,1) | 1/8 | 3  |\n",
    "\n",
    "\n",
    "<h3>Ejemplo de una variable aleatoria continua</h3> \n",
    "\n",
    "Tomemos $\\Omega=[0,1]$, con la $\\sigma$-algebra de Borel (la basada en los subconjuntos abiertos de $\\Omega$. $P$ es la medida de Lebesque en $\\Omega$, la cual corresponde a la longitud de los  subconjuntos de $\\Omega$. La variable aleatoria que definimos es $X(x) = 2x$.\n",
    "\n",
    "\n",
    "<h3>Función de distribución de probabilidad</h3> \n",
    "\n",
    "La distribución de probabilidad de una v.a. X, también llamada función de distribución de $X$ es la función ${\\displaystyle F_{X}(x)}$  que asigna a cada valor $x$ la probabilidad del subconjunto $(-\\infty,x]$ dada por:\n",
    "\n",
    "$$ F_{X}(x)=P(X\\leq x)$$,\n",
    "\n",
    "y de manera que se cumplan las siguientes tres condiciones:\n",
    "\n",
    "1. ${\\displaystyle \\lim _{x\\to -\\infty }F_X(x)=0}$ y ${\\displaystyle \\lim _{x\\to \\infty }F_X(x)=1}$ \n",
    "2.  $F_{X}(x)$ es continua por la derecha.\n",
    "3. $F_{X}(x)$ Es monótona no decreciente.\n",
    "\n",
    "En la teoría de probabilidad se demuestra que a cada variable aleatoria puede asociarse una única distribucón de probabilidad. Inversamente, dada uan función de distribución $F$, es posible asociarle casi siempre (c.s) una única variable aleatoria con dominio en un sunconjunto de $\\mathbb {R}$. Por esta razón usaremos la notación $F(x)$ para denotar una función de distribuciónde probabilidad.\n",
    "\n",
    "La variable aleatoria es **discreta**, si solamente toma valores en un subconjunto contable de ${\\displaystyle \\mathbb {R} }$. Se dice que la variable es **continua** si su correspondiente función de distribución es continua.\n",
    "\n",
    "- $\\leadsto$ La notación casi siempre (c.s) para indicar que una propiedad se cumple, excepto posiblemente sobre conjuntos de medida (probabilidad) cero. Por ejemplo, dos variables aleatorias son iguales casi siempre ($X=Y$ c.s) si coinciden en los valores que toman excepto posiblemente en conjuntos de medidad de probabildiad cero.\n",
    "\n",
    "<h3> Función de densidad de probabilidad </h3>\n",
    "\n",
    "La función de densidad de probabilidad (fdp) o, simplemente, función de densidad, representada comúnmente como $f(x)$, se utiliza con el propósito de conocer cómo se distribuyen las probabilidades de un suceso o evento, en relación al resultado del suceso.\n",
    "\n",
    "La fdp es la derivada (ordinaria o en el sentido de las distribuciones) de la función de distribución de probabilidad $F(x)$, o de manera inversa, la función de distribución es la integral de la función de densidad:\n",
    "\n",
    "$$ F(x)=\\int _{-\\infty }^{x}f(t)\\,dt$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.  Reglas básicas de Probabilidad </h2>\n",
    "\n",
    "Supongamos que $X$ y $Y$ son variables aleatorias. La probabilidad conjunta de   $X$ y $Y$ se denotará $P(X,Y)$.\n",
    "\n",
    "1. **Regla de la suma** (probabilidad marginal):  $P(X) = \\sum_Y P(X,Y)$, para el caso discreto y $P(X) = \\int_Y P(X,Y)dY$, en el caso contínuo.\n",
    "2. **Regla del producto** (probabilidad conjunat):  $P(X,Y) = P(X|Y)P(Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2> 3.  Teorema de Bayes </h2>\n",
    "\n",
    "\n",
    "Sea $\\{A_{1},A_{2},...,A_{i},...,A_{n}\\}$ un conjunto de sucesos mutuamente excluyentes y exhaustivos, y tales que la probabilidad de cada uno de ellos es distinta de cero (0). Sea $B$ un suceso cualquiera del que se conocen las probabilidades condicionales $P(B|A_{i})$. Entonces, Thomas Bayes (1702-1761) estableción que la probabilidad  $P(A_{i}|B)$ viene dada por la expresión:\n",
    "\n",
    "$$ P(A_{i}|B)={\\frac {P(B|A_{i})P(A_{i})}{\\sum_i P(B|A_i)P(A_i)}}= {\\frac {P(B|A_{i})P(A_{i})}{P(B)}}$$\n",
    "\n",
    "donde:\n",
    "\n",
    "- $P(A_i)$  son las probabilidades a priori, \n",
    "- $P(B|A_{i})$ es la probabilidad de $B$ bajo la hipótesis $A_i$, \n",
    "- $P(A_{i}|B)$ son las probabilidades a posteriori.\n",
    "\n",
    "\n",
    "\n",
    "Si $\\mathbf{\\theta}$ y $\\mathbf{x}$ representan vectores aleatorios, entonces, el teorema de Bayes establece que \n",
    "\n",
    "\n",
    "$$P(\\mathbf{\\theta}|\\mathbf{x}) = \\frac{P(\\mathbf{x}|\\mathbf{\\theta})P(\\mathbf{\\theta})}{\\int P(\\mathbf{x}|\\mathbf{\\theta})P(\\mathbf{\\theta})d\\mathbf{\\theta}} = \\frac{P(\\mathbf{x}|\\mathbf{\\theta})P(\\mathbf{\\theta})}{P(\\mathbf{x})}.$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h3> Discusión </h3>\n",
    "\n",
    "En la estadística Bayesiana se supone que tanto parámetros ($\\mathbf{\\theta}$) como observaciones ($\\mathbf{x}$) son variables aleatorias. Cuando se realiza un experimento de tipo estadístico, las observaciones se convierten en datos que podemos ver. Por otro lado, los parámetros se convierten en cantidades (parámetros numéricos) que no podemos observar directamente. Solamente podemos **inferir** el valor del parámetro a partir de los datos. Nótese que datos y los *parámetros numéricos* en el experimento son realizaciones de variables aleatorias. Los parámetros puede ser llamados variables latentes, en el sentido que están presentes y determinan las observaciones, pero no pueden ser observadas directamente.\n",
    "\n",
    "- $\\leadsto$ Piénse sobre esto y discuta en clase y con sus compañeros. \n",
    "\n",
    "[¿Cómo entender el teorema de Bayes en forma simple?](https://www.docirs.cl/entender_teorema_de_bayes_simple.asp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4. Pequeños Mundos y Grandes Mundos </h2>\n",
    "\n",
    "El propósito central de la Estadística es tratar de explorar, describir,... grandes mundos, a partir de pequeños mundos, mediante la utilización de modelos.\n",
    "\n",
    "En principio el(la) investigador(a) o interesado(a) en tales tareas tiene una idea inicial del mundo grande y construye un modelo para verificar sus hipótesis o para rechazarlas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> El mundo según Cristobal  Colon, 1492 </h3>\n",
    "\n",
    "Para el hombre de finales de s. XV, el mundo estaba compuesto por tres continentes: Europa, Asia y África. experto navegante y apasionado cartógrafo, decidió abrir una ruta marítima hacia Asia y se topó con un continente desconocido.\n",
    "\n",
    "Cristibal Colón fue un adelantado en su época. El creía que la tierra era redonda, y por eso se propuso llegar a Asia por el lado opuesto por el cual llegaba todo el mundo. El gráfico en el enlace es una  imagen de Martin Behaim de 1492, mostrando el pequeño mundo que Colón anticipó. [El mundo según  Colón, antes de sus viajes](https://es.m.wikipedia.org/wiki/Archivo:MartinBehaim1492.png)\n",
    "\n",
    "El error de Colón es que supuso que el diámetro de la tierra era de 300.000 kilómetros. En realidad son 40.000 kilometros aproximadamente. Por eso no preparó suficientes provisiones para el viaje. Este es un error que cambió al mundo.\n",
    "\n",
    "[Video: el mundo según Cristobal Colón](https://www.youtube.com/watch?v=zSHO24VFwyM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. Construyendo un modelo </h2> \n",
    "\n",
    "Supongamos que deseamos estimar el porcentaje de agua superficial del globo terráqueo. Al menos tres cosas debemos hacer:\n",
    "\n",
    "1. Narración de los datos: Motivar el modelo, narrando como los datos pueden o deben aparecer.\n",
    "2. Actualizar: Educar(entrenar) el modelo, alimentandolo con datos.\n",
    "3. Evaluar: Todos los modelos estadísticos requieren supervisón, llevando posiblemente a la revisón del modelo.\n",
    "\n",
    "\n",
    "Para nuestro primer modelo usaremos el lanzamiento de una moneda."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Narración de los datos </h3>\n",
    "\n",
    "El experimento consiste lanzar una modena y registrar el resultado: cara (1) o cruz (0).\n",
    "\n",
    "1. La probabilidad de *cara*, digamos $\\mu$,  corresponde al valor verdadero de la proporción de la veces que se espera que se obtenga cara. Por supuesto, si la moneda no es segada, todos sbameos a priori que $\\mu=0.5$. ¿Pero, y si la moneda esta sesgada? por ejemplo la moneda podría tener una deformación que hace más favorable un resultado. \n",
    "2. La probabilidad de *cara*  corresponde al valor verdadero de la proporción esperadas de caras.\n",
    "3. Cada experimento es independiente de los demás."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3> Actualización </h3>\n",
    "    \n",
    "1. Al comenzar asumiremos por facilidad que cualquier valor es igualmente plausible. Es decir, no nos inclinamos por ningún posible valor. No aportamos información acerca de nuestra **creencia** acerca de $\\mu$.\n",
    "2. Supondremos que a partir de las observaciones podemos construir una **distribución**. Luego de cada observación, tal distribución es actualizada.  Este proceso se llama **actualización Bayesiana**.\n",
    "\n",
    "La primera imagen en el siguiente enlace muestra la distribución a priori, antes de realizar el primer experimento.Las siguientes imágenes ilustran como se va actualizando la posterior, luego de realizar muchas veces el experimento. En este caso la moneda parece justa (insesgada). ¿Porque?\n",
    "\n",
    "[Actualización de la posterior a partir de la evidencia](https://s3.amazonaws.com/quantstart/media/images/qs-bayes-bernoulli.png)\n",
    "\n",
    " <h3> Ejercicio </h3>\n",
    " \n",
    "1. Escriba un programa Python que imite el experimento el experimento ilustrado. Pero ahora suponga que la moneda es sesgada. Por ejemplo, suponga que $\\mu=0.7$.\n",
    "\n",
    "- $\\leadsto$ Discuta estos resultados con sus compañeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escriba su solución aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <h3> Evaluación </h3>\n",
    "\n",
    "El modelo Bayesiano aprende de una forma que puede demostrarse que es optimal, lo que implica que el mundo grande real es descrito adecuadamente por el modelo. Es decir, nuestra **máquina Bayesiana** garantiza una inferencia perfecta, dentro del pequeño mundo. No hay otro camino mejor usando al información disponible.\n",
    "\n",
    " <h3> Upps </h3>\n",
    " \n",
    "Sin embargo no se entusiasme demasiado.\n",
    "\n",
    "Los cálculos pueden funcionar mal, entonces los resultados siempre tienen que ser verificados. Y si hay diferencias importantes entre\n",
    "el modelo y la realidad, entonces no hay una garantía lógica de un gran rendimiento global. \n",
    "\n",
    "\n",
    "Incluso si los dos mundos coincidieran, cualquier muestra particular de datos podría ser engañosa. Asi que\n",
    "vale la pena tener en cuenta al menos dos principios cautelosos.\n",
    "\n",
    "1. **La certeza del modelo no garantiza que el modelo sea bueno**. Como la cantidad\n",
    "de los aumentos de datos, el modelo de lanzamiento de globo crecerá cada vez más seguro de la proporción de\n",
    "agua. Esto significa que las curvas en la Figura se volverán cada vez más estrechas y altas,\n",
    "restringir valores plausibles dentro de un rango muy estrecho. Pero modelos de todo tipo: bayesianos o\n",
    "no, puede confiar mucho en una estimación, incluso cuando el modelo es muy engañoso.\n",
    "\n",
    "\n",
    "   Esto se debe a que **las estimaciones dependen del modelo**. \n",
    "\n",
    "2. Es importante supervisar y criticar el trabajo de su modelo. Considere nuevamente el\n",
    "hecho de que la actualización en la sección anterior funciona en cualquier orden de llegada de datos. Podríamos\n",
    "barajar el orden de las observaciones, mientras queden seis W y tres L, y aún así terminen\n",
    "con la misma curva de plausibilidad final. Sin embargo, eso solo es cierto porque el modelo supone\n",
    "ese **orden es irrelevante** para la inferencia. Pero, en algunos caso podría serlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Golems en Estadística</h3>\n",
    "\n",
    "[Sobre el golem de Praga](https://www.youtube.com/watch?v=KnTP-ZxFAzU)\n",
    "\n",
    "Los estadísticos usamos muchos golem. Por ejemplo en R usamos el golem lm() para hacer regresiones lineales como la siguiente: \n",
    "\n",
    "Para que el siguiente código corra en su ambiente Jupiter lab debe tener [instalado el kernel de R para Jupyter lab.](https://richpauloo.github.io/2018-05-16-Installing-the-R-kernel-in-Jupyter-Lab/)\n",
    "\n",
    "Arriba habilite el kernel para R arriba a la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A anova: 2 × 5</caption>\n",
       "<thead>\n",
       "\t<tr><th></th><th scope=col>Df</th><th scope=col>Sum Sq</th><th scope=col>Mean Sq</th><th scope=col>F value</th><th scope=col>Pr(&gt;F)</th></tr>\n",
       "\t<tr><th></th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>group</th><td> 1</td><td>0.688205</td><td>0.6882050</td><td>1.419101</td><td>0.2490232</td></tr>\n",
       "\t<tr><th scope=row>Residuals</th><td>18</td><td>8.729250</td><td>0.4849583</td><td>      NA</td><td>       NA</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A anova: 2 × 5\n",
       "\\begin{tabular}{r|lllll}\n",
       "  & Df & Sum Sq & Mean Sq & F value & Pr(>F)\\\\\n",
       "  & <int> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\tgroup &  1 & 0.688205 & 0.6882050 & 1.419101 & 0.2490232\\\\\n",
       "\tResiduals & 18 & 8.729250 & 0.4849583 &       NA &        NA\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A anova: 2 × 5\n",
       "\n",
       "| <!--/--> | Df &lt;int&gt; | Sum Sq &lt;dbl&gt; | Mean Sq &lt;dbl&gt; | F value &lt;dbl&gt; | Pr(&gt;F) &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|\n",
       "| group |  1 | 0.688205 | 0.6882050 | 1.419101 | 0.2490232 |\n",
       "| Residuals | 18 | 8.729250 | 0.4849583 |       NA |        NA |\n",
       "\n"
      ],
      "text/plain": [
       "          Df Sum Sq   Mean Sq   F value  Pr(>F)   \n",
       "group      1 0.688205 0.6882050 1.419101 0.2490232\n",
       "Residuals 18 8.729250 0.4849583       NA        NA"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# NOT RUN {\n",
    "require(graphics)\n",
    "\n",
    "## Annette Dobson (1990) \"An Introduction to Generalized Linear Models\".\n",
    "## Page 9: Plant Weight Data.\n",
    "ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)\n",
    "trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)\n",
    "group <- gl(2, 10, 20, labels = c(\"Ctl\",\"Trt\"))\n",
    "weight <- c(ctl, trt)\n",
    "lm.D9 <- lm(weight ~ group)\n",
    "lm.D90 <- lm(weight ~ group - 1) # omitting intercept\n",
    "# }\n",
    "# NOT RUN {\n",
    "anova(lm.D9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Discuta sobre porque lm() es un golem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Tarea </h3>\n",
    "\n",
    "<h3> Narración de los datos </h3>\n",
    "\n",
    "Para nuestra primera tarea usaremos un [globo terraqueo a escala.](https://es.wikipedia.org/wiki/Globo_terr%C3%A1queo#/media/Archivo:GlobeSK.jpg)\n",
    "\n",
    "1. El experimento consiste en hacer girar el globo y *pinchar* en algun lugar sin tener ninguna preferencia. El experimento es de tipo dicotómico, debido a que solamente\n",
    "habra dos posibles resultados: agua (1) o tierra (0).\n",
    "\n",
    "- La probabilidad de *pinchar* en agua corresponde al valor verdadero de la proporción de agua y se denotará $\\mu$.\n",
    "- La probabilidad de *pinchar* en tierra corresponde al valor verdadero de la proporción de tierra y es $ 1-\\mu$.\n",
    "- Cada experimento es independiente de los demás.\n",
    "\n",
    "2. Repita el proceso de actualización de la posterior en descrito en esta lección. Use Python y elabore algunos gráficos similares. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
