{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección Bayesiana de modelos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2. Guangyuan Gao, Bayesian Claims Reserving Methods in Non-life Insurance with Stan. An Introduction, Springer, 2018\n",
    "3. [\"Stan User's Guide. Version 2.22\", Stan Development Team, 2020.](https://mc-stan.org/users/documentation/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta lección revisamos herramientas estadísticas basadas en criterios de información para comparar modelos. \n",
    "\n",
    "En ocasiones es necesario seleccionar un modelo entre varios plausibles. Cuando se tiene varios modelos factibles para los datos y no se requiere seleccionar uno en particular, es mejor utlizarlos todos, mediante la técnica de promedio de modelos que veremos en otra lección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stacks_lasso = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> p;\n",
    "  real Y[N];\n",
    "  matrix[N,p] x;\n",
    "} \n",
    "\n",
    "// to standardize the x's \n",
    "transformed data {\n",
    "  real z[N,p];\n",
    "  real mean_x[p];\n",
    "  real sd_x[p];\n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] <- mean(col(x,j)); \n",
    "    sd_x[j] <- sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] <- (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta0; \n",
    "  real beta[p]; \n",
    "  real<lower=0> sigmasq; \n",
    "  real<lower=0> phi;\n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> sigma;\n",
    "  real mu[N];\n",
    "\n",
    "  sigma <- sqrt(2) * sigmasq;\n",
    "  for (n in 1:N)\n",
    "    mu[n] <- beta0 + beta[1] * z[n, 1] + beta[2] * z[n, 2] + beta[3] * z[n, 3];\n",
    "}\n",
    "\n",
    "model {\n",
    "  beta0 ~ normal(0, 316); \n",
    "  phi ~ gamma(0.01, 0.01);\n",
    "  beta ~ normal(0, sqrt(phi));\n",
    "  sigmasq ~ inv_gamma(.001, .001); \n",
    "  for (n in 1:N) \n",
    "    Y[n] ~ double_exponential(mu[n], sigmasq); \n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  real b0;\n",
    "  real b[p];\n",
    "  real outlier_1;\n",
    "  real outlier_3;\n",
    "  real outlier_4;\n",
    "  real outlier_21;\n",
    "\n",
    "  for (j in 1:p)\n",
    "    b[j] <- beta[j] / sd_x[j];\n",
    "  b0 <- beta0 - b[1] * mean_x[1] - b[2] * mean_x[2] - b[3] * mean_x[3];\n",
    "\n",
    "  outlier_1  <- step(fabs((Y[1] - mu[1]) / sigma) - 2.5);\n",
    "  outlier_3  <- step(fabs((Y[3] - mu[3]) / sigma) - 2.5);\n",
    "  outlier_4  <- step(fabs((Y[4] - mu[4]) / sigma) - 2.5);\n",
    "  outlier_21 <- step(fabs((Y[21] - mu[21]) / sigma) - 2.5);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El problema de selección del modelo es una negociación (trade-off) entre un modelo simple y un buen ajuste.\n",
    "\n",
    "Idealmente, queremos elegir el modelo más simple con el mejor ajuste.\n",
    "\n",
    "Sin embargo, los modelos que se adaptan bien tienden a ser más complicados, mientras que los modelos más simples tienden a ser poco adecuados.\n",
    "\n",
    "Los métodos de selección de modelos utilizados en la estadística frecuentista suelen ser los de de validación cruzada y los basados en criterios de información, que son la suma residual de cuadrados modificada con respecto a la complejidad del modelo y al sobreajuste.\n",
    "\n",
    "La validación cruzada mide el ajuste de un modelo en el conjunto de datos de prueba, que no es usado para ajustar el modelo, mientras que los criterios de información ajustan la medida de ajuste en el conjunto de datos de entrenamiento agregando una penalización por la complejidad del modelo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La precisión predictiva de un modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el marco Bayesiano, el ajuste de un modelo a veces se llama \n",
    "precisión predictiva del modelo (Gelman et al. 2014). Medimos la precisión predictiva de un modelo para un conjunto de datos $\\mathbf{z}$ por el logaritmo de densidad predictiva puntual (log point wise predictive density) o **lppd**,  el cual es calculado como sigue. Supongamos que $\\mathbf{y}$ es el conjunto de datos observados. Idealmente $\\mathbf{z}$ no debería ser usudo para ajustar el modelo.\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{lppd}:= \\log \\prod_{i=1}^{m} \\mathbb{E}_{\\boldsymbol{\\theta}| \\mathbf{y}} p( \\mathbf{z}|\\boldsymbol{\\theta}) = \\sum_{i=1}^{m} \\log (\\mathbb{E}_{\\boldsymbol{\\theta}| \\mathbf{y}} p(\\mathbf{z}|\\boldsymbol{\\theta})) = \\sum_{i=1}^{m} \\log \\left( \\int p(\\mathbf{z}|\\boldsymbol{\\theta}) p(\\theta| \\mathbf{y})d\\boldsymbol{\\theta} \\right).\n",
    "$$\n",
    "\n",
    "Si escogemos  $\\mathbf{z} = \\mathbf{y}$, obtenemos el lppd dentro de la muestra (within-sample) y los denotamos por $lppd_{train}$, el cual es típicamente mayor que el lppd fuera de muestra (out-of-sample)  el cual dnotamos por $lppd_{test}$. \n",
    "\n",
    "\n",
    "\n",
    "Para calcular **lppd** en la práctica, podemos evaluar la esperanza utilizando muestras de la distribución posterior $ p(\\boldsymbol{\\theta} | \\mathbf{y}) $, que etiquetamos como $ \\boldsymbol{\\theta}^{(t)}, t = 1, \\ldots, T$. El lppd calculado se define de la siguiente manera:\n",
    "\n",
    "\n",
    "$$\n",
    "\\text{computed } lppd:= \\sum_{i=1}^{n} \\log\\left( \\frac{1}{T} \\sum_{t=1}^{T} p(\\mathbf{z}|\\boldsymbol{\\theta}^{(t)})\\right).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la validación cruzada Bayesiana, los datos se dividen repetidamente en un conjunto de entrenamiento $\\mathbf{y}_{train} $ y un conjunto de pruebas $\\mathbf{y}_{test}$.\n",
    "\n",
    "\n",
    "Para simplificar, restringimos nuestra atención a la validación cruzada de dejar uno fuera, leave one out cross-validation(LOO-CV), donde $\\mathbf{y}_{test}$ solo contiene un punto de los datos. La estimación Bayesian LOO-CV de lppd fuera de muestra se define de la siguiente manera:\n",
    "\n",
    "$$\n",
    "lppd_{loo-cv} := \\sum_{i=1}^{n} \\log \\left( \\int p (y_i |\\boldsymbol{\\theta}) p (\\boldsymbol{\\theta}|\\mathbf{y}_{−i} ) d\\boldsymbol{\\theta}\\right).\n",
    "$$\n",
    "\n",
    "en donde $\\mathbf{y}_{−i}$ es el conjunto de datos omitiendo el  $i$-th punto. The $lppd_{loo-cv}$ puede calcularse como\n",
    "\n",
    "$$\n",
    "\\text{computed } lppd_{loo-cv} = \\sum_{i=1}^{n} \\log  \\left(\\frac{1}{T} \\sum_{t=1}^{T} p(y_i|\\theta^{(it)}) \\right),\n",
    "$$\n",
    "\n",
    "en donde $\\theta^{(it)}, t = 1, \\ldots , T$ son simulaciones de la distribución posterior $p(\\theta|\\mathbf{y}_{-i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criterios de información para selección de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de describir el DIC, revisamos otros dos criterios de información empleados en\n",
    "estadística frecuentistas. El criterio de información de Akaike (AIC) de Akaike (1973) es\n",
    "definido como\n",
    "\n",
    "$$\n",
    "AIC:= − 2\\sum_{i=1}^{n} \\log p (y_i |\\boldsymbol{\\theta}_{MLE}) + 2p.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "El criterio de información Bayesiano (BIC) de Schwarz (1978) se define como\n",
    "\n",
    "\n",
    "$$\n",
    "BIC:= − 2\\sum_{i=1}^{n} \\log p (y_i |\\boldsymbol{\\theta}_{MLE}) + p\\log n,\n",
    "$$\n",
    "\n",
    "en donde $ p $ es el número de parámetros. El primer término común $ - 2 \\sum_ {i = 1}^ {n} \\log p (y_i | \\boldsymbol{\\theta}_ {MLE}) $ es la deviance, la cual  mide la discrepancia entre el modelo ajustado y los datos. El segundo término mide la complejidad del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIC: Deviance Information Criterion DIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En el marco Bayesiano, definimos una cantidad similar para medir la discrepancia,\n",
    "$ -2 \\sum_ {i = 1} ^ {n} \\log p (y_i | \\hat{\\theta}) $, donde $ \\hat{\\theta} $ es la media posterior. \n",
    "\n",
    "Spiegelhalter et. al. (2002) propusieron una medida del número de parámetros efectivos, que se define como la diferencia entre la media posterior de la desviación y la desviación en la media posterior, como sigue:\n",
    "\n",
    "\n",
    "$$\n",
    "p_D := \\widehat{D (\\boldsymbol{\\theta})} - D(\\hat{\\boldsymbol{\\theta}}) = −2\\mathbb{E}_{\\theta|y} \\left(\\sum_{i=1}^{n} \\log p (y_i |\\boldsymbol{\\theta})\\right) + 2 \\sum_{i=1}^{n} \\log p(y_i|\\hat{\\boldsymbol{\\theta}}),\n",
    "$$\n",
    "\n",
    "en donde $D$ es la deviance definida arriba.\n",
    "\n",
    "Observe que el cálculo práctico se tiene que si $\\boldsymbol{\\theta}^{(t)}$ es una muestra de tamaño $T$ de la posterior $p(\\boldsymbol{\\theta}|\\mathbf{y})$, entonces\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\widehat{D (\\boldsymbol{\\theta})}&\\approx \\frac{-2}{T}\\sum_{t=1}^{T}\\left(\\sum_{i=1}^{n} \\log p (y_i |\\boldsymbol{\\theta}^{(t)})\\right)\\\\\n",
    "\\hat{\\boldsymbol{\\theta}}&\\approx \\frac{1}{T}\\sum_{t=1}^{T} \\boldsymbol{\\theta}^{(t)}.\n",
    " \\end{align}\n",
    "$$\n",
    "\n",
    "Los autores propusieron además un criterio de información de deviance (DIC), definido como\n",
    "la deviance en las medias posteriores más el doble del número efectivo de parámetros,\n",
    "con lo que se obtiene\n",
    "\n",
    "$$\n",
    "DIC := D( \\hat{\\boldsymbol{\\theta}}) + 2p_D.\n",
    "$$\n",
    "\n",
    "\n",
    "DIC es visto como un análogo Bayesiano de AIC. Preferimos el modelo con menor DIC.\n",
    "\n",
    "Hay que tener en cuenta que DIC y $ p_D $ son sensibles al nivel en un modelo jerárquico. \n",
    "\n",
    "Entonces DIC es más apropiado cuando estamos interesados en los parámetros directamente relacionados con los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WAIC: Criterio de información de  Watanabe-Akaike (widely available information criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Watanabe (2010) propuso otra medida del número de parámetros efectivos de la siguiente manera:\n",
    "\n",
    "$$\n",
    "p_{WAIC} := \\widehat{D(\\theta)} + 2lppd_{train} = −2\\mathbb{E}_{\\theta|y} \\left(\\sum_{i=1}^{n} \\log p (y_i |\\theta) \\right) + 2 \\sum_{i=1} ^{n} \\log \\left( \\mathbb{E}_{\\theta|y} p (y_i |\\theta)\\right),\n",
    "$$\n",
    "\n",
    "en donde $−2lppd_{train}$ juega un rol como $D(\\hat{\\theta})$ en  $p_D$. Como con AIC y DIC, WAIC se define por\n",
    "\n",
    "$$\n",
    "WAIC:= − 2lppd_{train} + 2p_{WAIC}.\n",
    "$$\n",
    "\n",
    "Se ha encontrado que este criterio es en general más robusto que el DIC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterio Leave-One-Out Information Criterion (LOOIC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Diferente de la definición del número de parámetros efectivos en AIC, DIC y\n",
    "WAIC, definimos\n",
    "\n",
    "$$\n",
    "p_{loo} := lppd_{train} − lppd_{loo-cv},\n",
    "$$\n",
    "\n",
    "en donde $lppd_{loo-cv}$ se calcula como se muestra arriba. The criterio leave-one-out information criterion (LOOIC) se define como\n",
    "\n",
    "$$\n",
    "LOOIC:= − 2lppd_{train} + 2p_{loo} = −2lppd_{loo-cv},\n",
    "$$)\n",
    "el cual es razonable debido a que $lppd_{loo-cv}$ ya penaliza el sobreajuste (overfitting)\n",
    "(o de manera equivalente la complejidad del modelo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los modelos propuestos para los datos de stack loss, escriba el código para calcular los criterios DIC, WAIC y LOOIC.\n",
    "\n",
    "Haga una tabla comparativa que colocando acad modelo, el número de parámetros efectivos y el valor del criterio."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
