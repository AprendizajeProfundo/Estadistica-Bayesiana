{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cálculo el Factor de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.  Cong HAN and Bradley P CARLIN, *Markov Chain Monte Carlo Methods for Computing Bayes Factors: A Comparative Review*, Journal of the American Statistical Association, Vol. 96, No. 455 (Sep., 2001), pp. 1122-1132.\n",
    "\n",
    "2. Adrian Raftery, [Hypothesis Testing and Model Selection Via Posterior Simulation](https://www.stat.washington.edu/sites/default/files/Other%20Online/test-postsim.pdf), Research report, Washintong University, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos con datos $\\mathbf{y}$, de los cuales se asume que son generados por uno de los dos modelos $M_0$ or $M_1$, de acuerdo con la densidad de probabilidad  $pr(\\mathbf{y} | M_0)$ or $pr(\\mathbf{y} | M_1)$.\n",
    "\n",
    "La cantidad $B_{10}$ es definda por \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "B_{10}= \\frac{Pr[\\mathbf{y}|M_1]}{Pr[\\mathbf{y}|M_0]}=\\frac{\\text{ odds posterior}}{\\text{odds a priori}},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "y es llamadas el  **factor de Bayes**. El factor de Bayes mide el peso de la evidencia en favor de $M_1$ en contra de  $M_0$.\n",
    " \n",
    "\n",
    "\n",
    "La intuición básica es que la información previa y posterior son combinado en una proporción que proporciona evidencia a favor de un modelo especificación versus otra.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "El uso de factores de Bayes es el método dominante de las pruebas de modelos Bayesianos, y son los análogos Bayesianos de las pruebas de razón de verosimilitud."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretación del Factor de Bayes. Regla de combate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El factor de Bayes en favor del modelo $M_1$ en contra del modelo $M_0$ es dado por\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "B_{10} = \\frac{p(H_1|\\mathbf{y})/p(H_0|\\mathbf{y})}{p(H_1)/p(H_0)},\n",
    "\\end{equation*}\n",
    "$$\n",
    "y la respectiva probabilidad posterior del modelo  1 denotada $\\pi_1 = P(H_1|\\mathbf{y})$ es dada por\n",
    "\n",
    "$$\n",
    "\\pi_1=\\frac{p_1 B_{10}}{p_1 B_{10} + 1- P_1}\n",
    "$$\n",
    "\n",
    "Con esta configuración, si interpretamos el modelo 0 como el modelo nulo, se tiene que el factor de Bayes puede interpretarse de acuerdo con la siguiente regla práctica propuesta por los expertos. Véa las referencias de la lección arriba. \n",
    "\n",
    "\n",
    "\n",
    "<h4> <center><span class=\"header-section-number\"></span> Interpretación práctica del factor de Bayes </center></h4>\n",
    "\n",
    "|$B_{10}$|<div style=\"width:65px\">$2\\log B_{10}$ </div>|Evidencia en favor de $M_1$| \n",
    "|---|---|---|\n",
    "|<$\\hspace{1mm}1$ | <$\\hspace{1mm} 0$ |Negativa. Los datos soportan $M_0$|\n",
    "|1 to 3 | 0 to 2           |No importante. Apenas para mencionarlo|\n",
    "|2 to 12| 2 to 5 |Positiva|\n",
    "|12  to 150| 5 to 10|Fuerte|\n",
    "|>$\\hspace{1mm}$150| >$\\hspace{1mm}$ 10 |Muy fuerte|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproximación  normal de la distribución posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aproximación de Laplace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comúnmente, la posterior se conoce hasta una constante proporcional, es decir, solamente $\\pi^*$ se conocido, en donde $\\pi^*(\\theta) = l(\\theta)p(\\theta) = k\\pi(\\theta)$ con $k= \\int \\pi^*(\\theta)d\\theta$.\n",
    "\n",
    "\n",
    "Entonces tenemos que\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\pi^*(\\theta) &\\approx \\pi^*(m)  \\exp \\left\\{ \\frac{1}{2} (\\theta-m)' \\left[ -\\frac{\\partial^2 \\log \\pi^*(m)}{\\partial\\theta \\partial \\theta'}  \\right](\\theta-m) \\right\\}\\\\\n",
    "&= \\pi^*(m)  \\exp \\left\\{ \\frac{1}{2} (\\theta-m)' V^{-1}(\\theta-m), \\right\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "por lo que\n",
    "\n",
    "$$\n",
    "k= \\pi^*(m)(2\\pi)^{d/2}|V|^{1/2},\n",
    "$$\n",
    "\n",
    "en donde\n",
    "\n",
    "$$\n",
    "V=  \\left[ -\\frac{\\partial^2 \\log \\pi(m)}{\\partial\\theta \\partial \\theta'}  \\right]^{-1}= \\left[ -\\frac{\\partial^2 \\log \\pi^*(m)}{\\partial\\theta \\partial \\theta'}  \\right]^{-1} \n",
    "$$\n",
    "\n",
    "Entonces, de manera  aproximada se tiene que, $\\theta \\sim N(\\widehat{\\theta}, I^{-1}(\\widehat{\\theta}))$, y $I(\\widehat{\\theta})$ puede ser la matriz de información de Fisher o la matriz de información observada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimación de la verosimiltud predictiva usando la aproximación normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aproximación normal de la posterior lleva a la estimación\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "f(\\mathbf{y}) \\approx f(\\mathbf{y}|\\mathbf{m}) \\pi(\\mathbf{m})(2\\pi)^{d/2} |V|^{1/2},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "la cual se basa en la evaluación de la moda posterior  $\\mathbf{m}$.\n",
    "\n",
    "Una aproximación muestral (método MC)   para  $\\mathbf{m}$ y $V$ puede ser construida  a partir de la muestra Bayesiana $\\boldsymbol{\\theta}_1,\\ldots,\\boldsymbol{\\theta}_n$  obtienida de la distribución posterior\n",
    "\n",
    "\n",
    "La moda $\\mathbf{m}$  puede ser estimada a partir de la moda de la muetra Bayesiana. Es decir,\n",
    " $\\hat{\\mathbf{m}}$ se estima como el valor para el cual la posterior en la muestra alcanza el valor más grande. Así se tiene que\n",
    " \n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{m}} = \\max_j\\{ \\pi(\\boldsymbol{\\theta_j}) \\}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Similarmente se tiene que\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{V} = \\tfrac{1}{n} \\sum_{j=1}^n (\\boldsymbol{\\theta}_j - \\bar{\\boldsymbol{\\theta}})(\\boldsymbol{\\theta}_j - \\bar{\\boldsymbol{\\theta}})^t, \\text{ where } \\bar{\\boldsymbol{\\theta}} = \\sum_{j=1}^n \\boldsymbol{\\theta}_j.\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El factor de Bayes a partir de la estimación de la densidad marginal de las observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El Factor de Bayes en el caso de muestras grandes de observaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si $n$  es grande y las observaciones son independientes, por lo general, la densidad posterior $ l_n (\\theta) + \\pi (\\theta) $ tiene un pico agudo en la vecindad de la moda posterior $ \\widetilde {\\theta} $. Por lo tanto, se podría utilizar la aproximación de Laplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename=\"D:/home/Bayesian_Course/images/PosteriorMode.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea $d$ la dimensión del vector $\\boldsymbol{\\theta}$. Supongamos quie la posterior es unimodal. La expansión de Taylor de segundo orden del logaritmo de la posterior alrededor  de la única moda  $\\widetilde{\\boldsymbol{\\theta}}$ es dada por\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\log l_n(\\boldsymbol{\\theta}) + \\log\\pi(\\boldsymbol{\\theta}) \\approx  \\log l_n(\\widetilde{\\boldsymbol{\\theta}}) + \\log\\pi(\\widetilde{\\boldsymbol{\\theta}}) + ( \\boldsymbol{\\theta} -\\widetilde{\\boldsymbol{\\theta}} )^t\\nabla^2(\\log l_n(\\widetilde{\\boldsymbol{\\theta}}) + \\log\\pi(\\widetilde{\\boldsymbol{\\theta}}))( \\boldsymbol{\\theta} -\\widetilde{\\boldsymbol{\\theta}} ),\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "en donde \n",
    "\n",
    "$$\n",
    "\\nabla^2(\\log l_n(\\widetilde{\\boldsymbol{\\theta}}) + \\log\\pi(\\widetilde{\\boldsymbol{\\theta}}))\n",
    "$$\n",
    "\n",
    "\n",
    "es la matriz Hessiana de segundas derivadas, evaluada en  $\\widetilde{\\boldsymbol{\\theta}}$. Sea\n",
    "\n",
    "$$\n",
    "\\widetilde{\\boldsymbol{\\Sigma}} = -\\left[\\nabla^2(\\log l_n(\\widetilde{\\boldsymbol{\\theta}}) + \\log\\pi(\\widetilde{\\boldsymbol{\\theta}}))\\right]^{-1}.\n",
    "$$ \n",
    "\n",
    "\n",
    "La aproximación de  Laplace en este caso es dada por \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "f(\\mathbf{y}) = \\int f(\\mathbf{y}|\\boldsymbol{\\theta})\\pi(\\boldsymbol{\\theta})d\\boldsymbol{\\theta} \\approx (2\\pi)^{d/2} |\\widetilde{\\boldsymbol{\\Sigma}}|^{1/2} f(\\mathbf{y}|\\widetilde{\\boldsymbol{\\theta}})\\pi(\\widetilde{\\boldsymbol{\\theta}})= \\tilde{f}(\\mathbf{y}).\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Bajo ciertas condiciones de regularidad se tiene que  $f(\\mathbf{y}) =\\tilde{f}(\\mathbf{y})+ O(n^{-1})$. Véa por ejemplo Kass, Tierney, Kadane, 1990."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación al factor de Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Supongamos que tenemos dos modelos $ M_0 $ y $ M_1 $ para comparar. Sea $ \\boldsymbol {\\pi} _0 $ el parámetro para el modelo $ M_0 $ y definamos $ \\widetilde {\\boldsymbol {\\theta} _0} $, $ \\widetilde {\\boldsymbol{\\Sigma} _0} $ y $ d_0 $  como la moda posterior correspondiente, la matriz de Hessiana evaluada en la moda posterior  y la dimensión del vector $ \\boldsymbol{\\theta}_0 $ respectivamente. Se hacen definiciones similares para el modelo 1.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Por lo tanto, tenemos que la aproximación de Laplace del logaritmo del factor de Bayes $ B_{10} $ a favor del modelo 1 viene dada por\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "2 \\log B_{10} =  &2\\log f(\\mathbf{y}|M_1) - 2 \\log f(\\mathbf{y}|M_2)\\\\\n",
    "= &[\\log(\\tilde{\\boldsymbol{\\Sigma}_1 }) - \\log(\\tilde{\\boldsymbol{\\Sigma}_0})] + (d_1-d_0)\\log(2\\pi) \\\\\n",
    "& + 2\\left[\\sum_i \\log f(y_i| \\tilde{\\boldsymbol{\\theta}_1}) - \\sum_i \\log f(y_i| \\tilde{\\boldsymbol{\\theta}_0})\\right]\n",
    "+ 2(\\log \\pi(\\tilde{\\boldsymbol{\\theta}_1}) - \\log \\pi(\\tilde{\\boldsymbol{\\theta}_0}))\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "En modelos anidados $\\boldsymbol{\\theta}_0$ es un subconjunto de $\\boldsymbol{\\theta}_1$  y $(d_1-d_0)$ es la diferencia de los tamaños de los respectivos vectores de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproximaciones de Monte Carlo de la probabilidad predictiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimador ingenuo (naive estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\leadsto$ Esta sección está basada en el libro de Gammerman, capítulo 7.\n",
    "\n",
    "\n",
    "Para cualquier modelo Bayesiano $M$ la densidad predictiva es dada por\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "f(y|M) = \\int f(y|\\theta,M)p(\\theta|M)d\\theta = E[f(y|\\theta)].\n",
    "\\end{equation*}\t\n",
    "$$\n",
    "\n",
    "Si la a priori coincide aproximadamente con la verosimilitud, el siguiente estimador funciona aceptablemente  bien. \n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{f}_1(y) = \\frac{1}{N}\\sum_{j=1}^{N} f(y|\\theta_j),\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "en donde  $\\theta_1,\\ldots,\\theta_n $ es una muestra de la apriori $p(\\theta|M)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Densidad de importancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Si la apriori no es similar a la verosimilitud, una mejor opción es usar una densidad de importancia para aumentar la muestra en regiones donde el integral es grande. Sea $ g (\\theta) = kg^*(\\theta) $ una densidad de importancia no normalizada. Así\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{f}_2(y) = \\frac{1}{N}\\sum_{j=1}^{N} \\frac{f(y|\\theta_j)p(\\theta_j)}{g(\\theta_j)},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "en donde $\\theta_1,\\ldots,\\theta_n $ es una muestra de la posterior $g(\\theta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Densidad de importancia con $k$ deconocido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando la constrante de normalización se deconoce  se puede tener en cuenta que\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "k = \\int k p(\\theta)d\\theta = \\int \\frac{p(\\theta)}{g^*(\\theta)}g(\\theta)d\\theta.\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "En consecuencia,\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{k} = \\frac{1}{n}\\sum_{j=1}^{n} p(\\theta_j)/g^*(\\theta_j).\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Reemplazando esta aproximación en $\\widehat{f}_2$ se obtiene\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{f}_3(y) = \\frac{ \\sum_{j=1}^{n}f(y|\\theta_j)p(\\theta_j)/g^*(\\theta_j)}{\\sum_{j=1}^{n} p(\\theta_j)/g^*(\\theta_j)}.\n",
    "\\end{equation*}\t\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimador media armónica de la verosimilitud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se utiliza la posterior como densidad de importancia, con lo que se tiene que $g(\\theta)= \\pi(\\theta|y)$. \n",
    "\n",
    "Debido a que después de un procedimiento MCMC se tiene una muestra disponible de $\\pi(\\theta|y) = k f(y|\\theta)p(\\theta)$, se pueden usar estos valores en $\\widehat{f}_3$ with $g^*(\\theta)= f(y|\\theta)p(\\theta)$ para obtener\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{f}_4(y) = \\left[\\frac{1}{N}\\sum_{j=1}^{N} \\frac{1}{f(y|\\theta_j)}\\right]^{-1}.\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "Este estimador es inestable si valores muy bajos de $f(y|\\theta_j)$ son posibles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combinación de estimadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos la densidad de importancia $g(\\theta)= \\delta p(\\theta) + (1-\\delta)\\pi(\\theta|y)$, en doende se asume que $0<\\delta<1$. Este estimador es un compromiso entre $\\widehat{f}_1$ y $\\widehat{f}_4$. \n",
    "\n",
    "\n",
    "Supongamos que tenemos una muestra de  $g(\\theta)$. El problema es que $f(y|\\theta)$ se requiere para la evaluacion de  $\\pi(\\theta|y)$. \n",
    "\n",
    "Entonces el siguiente esquema iterativo de estimación es sugerido:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\widehat{f}_5^{(t)}(y) = \\frac{\\sum_{j=1}^{n}f(y|\\theta_j)\\{\\delta\\hat{f}_5^{(t-1)} (y) + (1-\\delta)f(y|\\theta_j)\\}^{-1}} {\\sum_{j=1}^{n}\\{\\delta\\hat{f}_5^{(t-1)} (y) + (1-\\delta)f(y|\\theta_j)\\}^{-1}}\n",
    "\\end{equation*}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
