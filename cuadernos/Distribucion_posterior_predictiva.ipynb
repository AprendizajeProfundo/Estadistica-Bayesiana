{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución posterior predictiva\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2. Guangyuan Gao, \"Bayesian Claims Reserving Methods in Non-life Insurance with Stan. An Introduction\", Springer, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "En esta lección, revisamos el concepto de distribución predictiva. Esta distribución es la base de las herramientas para el chequeo de los modelos. \n",
    "\n",
    "Usaremos la distribución predictiva para predecir datos no observados, y para replicar datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión de la predictiva posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "En el marco Bayesiano, idealmente queremos dividir los datos en un conjunto de entrenamiento y un conjunto de prueba y hacer la verificación predictiva posterior en el conjunto de datos de prueba.\n",
    "\n",
    "\n",
    "Alternativamente, podemos elegir una estadística de prueba cuya distribución predictiva no dependa de parámetros desconocidos en el modelo, sino principalmente de la hipótesis que se verifica.\n",
    "\n",
    "\n",
    "Entonces no hay necesidad de tener un conjunto de datos de prueba por separado. Sin embargo, cuando se usan los mismos datos para ajustar y verificar el modelo, esto debe llevarse a cabo con precaución, ya que el\n",
    "el procedimiento puede ser conservador.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribución predictiva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La distribución predictiva es la distribución de observaciones futuras dada la muestra actual.\n",
    "\n",
    "Supongamos que $ y_ {n + 1} $ es una observación futura que es independiente de los datos observados $ \\mathbf{y}$, dado el correspondiente parámetro $\\boldsymbol{\\theta}$. \n",
    "\n",
    "\n",
    "Entonces, la distribución predictiva para $ y_{n + 1} $ viene dada por\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "p(y_{n+1}|\\mathbf{y}).\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Observe que\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(y_{n+1}|\\mathbf{y})&=\\int\n",
    "p(y_{n+1},\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta}\\\\\n",
    "&= \\int\n",
    "f(y_{n+1}|\\mathbf{\\theta},\\mathbf{y})p(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta}\\\\\n",
    "&=\\int\n",
    "f(y_{n+1}|\\mathbf{\\theta})p(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Es decir que\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "p(y_{n+1}|\\mathbf{y}) = \\int\n",
    "f(y_{n+1}|\\mathbf{\\theta})p(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "y en consecuencia los valores predichos pueden ser calculados dentro del algorimo de muestreo.  Supongamos que en el paso $m$ después de convergencia se tiene que la muestra para $\\boldsymbol{\\theta}$ es $\\boldsymbol{\\theta}^{(m)}$. Entonces un valor predictivo puede ser obtenido a partir de la densidad posterior\n",
    "predictiva\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "f(y|\\mathbf{\\theta}^{(m)})\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Dentro del algoritmo de muestreo se procede así: en el paso $m$\n",
    "\n",
    "1. Se obtiene la muestra $\\mathbf{\\theta}^{(m)} \\sim p(\\mathbf{\\theta}|\\mathbf{y})$ (sección *model* de Stan).\n",
    "2. Se obtiene el valor predicho $y_{n+1} \\sim f(y|\\mathbf{\\theta}^{(m)})$ (sección *generated quantities* de Stan).\n",
    "\n",
    "Observe que en el numeral 2, se está usando la función de verosimilitud (que es una densidad) con parámetro $\\mathbf{\\theta}^{(m)}$.\n",
    "\n",
    "Cada observación $y_i$ en el caso de los modelos de regresión  depende no solamente del parámetro $\\mathbf{\\theta}$, sino también de un vector de variables regresoras o predictoras $\\mathbf{x}_i$. En este caso tenemos que la posterior predictiva es dada por \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "p(y_{n+1}|\\mathbf{y},x_{n+1}) = \\int\n",
    "f(y_{n+1}|\\mathbf{\\theta},x_{n+1})p(\\mathbf{\\theta}|\\mathbf{y})d\\mathbf{\\theta},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción de datos no observados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección usamos el modelo de regresión Binomial para ilustrar la predicción de datos no observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo Modelo de Regresión Binomial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la lección [Modelos Bayesianos de regresión](./Modelos_Bayesianos_Regresion.ipynb) introdujimos el modelo de regresión Binomial dado por\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "E[y_i] &= \\mu_i= N_i\\pi_i\\\\\n",
    "\\pi_i &=  \\text{inv_logit}(\\alpha +  \\mathbf{x_i}^T\\mathbf{\\beta}) \\\\\n",
    "\\alpha &\\sim \\mathcal{N}(\\mu_{\\alpha},\\sigma_{\\alpha}^2)\\\\\n",
    "\\mathbf{\\beta} &\\sim \\mathcal{N}(\\mathbf{\\mu}_{\\beta},\\rho_{\\beta}^2\\mathbf{I})\\\\\n",
    "y_i &\\sim \\text{Binomial}(N_i,\\pi_i), \\hspace{3mm} i =1,\\ldots,n.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Aqui cada observación $y_i$ depende de $\\pi_i$ y de su vector predictor $\\mathbf{x}_i$. Supongamos que $\\alpha^{(m)}$ y $\\mathbf{\\beta}^{(m)}$ son las muestras respectivamente de $\\alpha$ y $\\mathbf{\\beta}$  en el paso $m$ del algortimo de muestreo. Entonces una muestra $y_*$ (no observada) en este paso dado el vector predictor $\\mathbf{x}_*$, el cual no hace parte de los datos se obtiene como sigue. Sea $N_*$ el número de ensayos, y denotemos por $y_*^{(m)}$ la predicción de $y_*$  en el paso $m$. Entonces se tiene  que\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "{\\pi}_*^{(m)} &=  \\text{inv_logit}(\\alpha^{(m)} +  \\mathbf{x}_*^T{\\mathbf{\\beta}^{(m)}}) \\\\\n",
    "y_*^{(m)} & \\sim \\text{Binomial}(N_*,{\\pi}_*^{(m)}) \n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "En Stan $\\alpha$ y $\\mathbf{\\beta}$  son obtenidos en la sección *model* y los dos pasos anteriores para obtener la predicción son escritos en la sección *generated quantities*.\n",
    "\n",
    "El siguiente fragmento de código ilustra como implementar el algoritmo anterior. La variable *y_pred* es utilizada para hacer la prediccón en cada paso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic STAN\n",
    "import pystan\n",
    "%load_ext stanmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pystan.stanc compiler..\n",
      "-------------------------------------------------------------------------------\n",
      "Model compiled successfully. Output stored in _stan_model object.\n",
      "Type _stan_model in a cell to see a nicely formatted code output in a notebook\n",
      "     ^^^^^^^^^^^\n",
      "Access model compile output properties\n",
      "_stan_model.model_file -> Name of stan_file [binomial_reg.stan]\n",
      "_stan_model.model_name -> Name of stan model [binomial_reg_model]\n",
      "_stan_model.model_code -> Model code [//  Binomial Regress ....]\n"
     ]
    }
   ],
   "source": [
    "%%stan -f binomial_reg.stan\n",
    "//  Binomial Regression  Model\n",
    "// Prediction of non-observed data\n",
    "\n",
    "data{\n",
    "int<lower=0> n; // número de datos\n",
    "int<lower=0> p; // número de variables predictoras\n",
    "int<lower=0> N[n]; // número de ensayos para cada observación\n",
    "int<lower=0> y; // datos observados\n",
    "matrix[n,p] X; // variables predictoras observadas\n",
    "vector[n] x_p; // vector predictor no observado\n",
    "int<lower=0> Np; // Número de ensayos para la predicción\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    real alpha;\n",
    "    vector[p] beta;   \n",
    "}\n",
    "\n",
    "transformed parameters{\n",
    "  vector<lower=0,upper=1>[n] pi; \n",
    "  pi = inv_logit(alpha + X * beta);\n",
    "}\n",
    "\n",
    "\n",
    "model{\n",
    "  // priors\n",
    "  alpha ~ normal(0,10);\n",
    "  beta ~ normal(0,10);\n",
    "  // likelihood   \n",
    "  y ~ binomial_logit(N, pi);\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    real y_pred;\n",
    "    real pp;\n",
    "    pp = inv_logit(alpha + dot_product(x_p,beta));\n",
    "    y_pred = binomial_rng(Np,pp);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stacks_lasso = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> p;\n",
    "  real Y[N];\n",
    "  matrix[N,p] x;\n",
    "} \n",
    "\n",
    "// to standardize the x's \n",
    "transformed data {\n",
    "  real z[N,p];\n",
    "  real mean_x[p];\n",
    "  real sd_x[p];\n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] <- mean(col(x,j)); \n",
    "    sd_x[j] <- sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] <- (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta0; \n",
    "  real beta[p]; \n",
    "  real<lower=0> sigmasq; \n",
    "  real<lower=0> phi;\n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> sigma;\n",
    "  real mu[N];\n",
    "\n",
    "  sigma <- sqrt(2) * sigmasq;\n",
    "  for (n in 1:N)\n",
    "    mu[n] <- beta0 + beta[1] * z[n, 1] + beta[2] * z[n, 2] + beta[3] * z[n, 3];\n",
    "}\n",
    "\n",
    "model {\n",
    "  beta0 ~ normal(0, 316); \n",
    "  phi ~ gamma(0.01, 0.01);\n",
    "  beta ~ normal(0, sqrt(phi));\n",
    "  sigmasq ~ inv_gamma(.001, .001); \n",
    "  for (n in 1:N) \n",
    "    Y[n] ~ double_exponential(mu[n], sigmasq); \n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  real b0;\n",
    "  real b[p];\n",
    "  real outlier_1;\n",
    "  real outlier_3;\n",
    "  real outlier_4;\n",
    "  real outlier_21;\n",
    "\n",
    "  for (j in 1:p)\n",
    "    b[j] <- beta[j] / sd_x[j];\n",
    "  b0 <- beta0 - b[1] * mean_x[1] - b[2] * mean_x[2] - b[3] * mean_x[3];\n",
    "\n",
    "  outlier_1  <- step(fabs((Y[1] - mu[1]) / sigma) - 2.5);\n",
    "  outlier_3  <- step(fabs((Y[3] - mu[3]) / sigma) - 2.5);\n",
    "  outlier_4  <- step(fabs((Y[4] - mu[4]) / sigma) - 2.5);\n",
    "  outlier_21 <- step(fabs((Y[21] - mu[21]) / sigma) - 2.5);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producción de datos replicados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En los métodos de validación del modelo es común replicar los datos observados. Replicar un dato significa \"predecir un dato observado\". La diferencia con el caso anterior es que ahora para replicar el dato se utiliza el predictor de los datos observados.\n",
    "\n",
    "De acuerdo con la notación de l a sección anterior, para replicar el dato $y_i$, se usará su predictor $\\mathbf{x_i}$.\n",
    "\n",
    "Para ilustar la replica de datos en el modelo de regresión binomial refactorizamos el código anterior. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Réplica de observaciones en el modelo de regresión Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic STAN\n",
    "import pystan\n",
    "%load_ext stanmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pystan.stanc compiler..\n",
      "-------------------------------------------------------------------------------\n",
      "Model compiled successfully. Output stored in _stan_model object.\n",
      "Type _stan_model in a cell to see a nicely formatted code output in a notebook\n",
      "     ^^^^^^^^^^^\n",
      "Access model compile output properties\n",
      "_stan_model.model_file -> Name of stan_file [binomial_reg_2.stan]\n",
      "_stan_model.model_name -> Name of stan model [binomial_reg_2_model]\n",
      "_stan_model.model_code -> Model code [//  Binomial Regress ....]\n"
     ]
    }
   ],
   "source": [
    "%%stan -f binomial_reg_2.stan\n",
    "//  Binomial Regression  Model\n",
    "// Replication of observed data\n",
    "\n",
    "data{\n",
    "int<lower=0> n; // número de datos\n",
    "int<lower=0> p; // número de variables predictoras\n",
    "int<lower=0> N[n]; // número de ensayos para cada observación\n",
    "int<lower=0> y; // datos observados\n",
    "matrix[n,p] X; // variables predictoras observadas\n",
    "}\n",
    "\n",
    "parameters{\n",
    "    real alpha;\n",
    "    vector[p] beta;   \n",
    "}\n",
    "\n",
    "transformed parameters{\n",
    "  vector<lower=0,upper=1>[n] pi; \n",
    "  pi = inv_logit(alpha + X * beta);\n",
    "}\n",
    "\n",
    "\n",
    "model{\n",
    "  // priors\n",
    "  alpha ~ normal(0,10);\n",
    "  beta ~ normal(0,10);\n",
    "  // likelihood   \n",
    "  y ~ binomial_logit(N, pi);\n",
    " k ~ binomial (Np,)...\n",
    "}\n",
    "\n",
    "generated quantities {\n",
    "    int y_rep[n];\n",
    "    vector[n] pp;\n",
    "    pp = inv_logit(alpha + X * beta);\n",
    "    y_rep = binomial_rng(N,pp);\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Consulte un conjunto de datos para una regresión Binomial. Consulte por ejemplo el texto del profesor Gilberto de Paula o en los ejemplos de Gamlss.\n",
    "2. Modifique los códigos para los modelos de  la [lección de modelos Bayesianos de regresión](./Modelos_Bayesianos_Regresion.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "traces = fit_lasso.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
