{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Bayesian Course</center></h1>\n",
    "\n",
    "<h2>Lecture 27: Model Assessment and Selection</h2>\n",
    "\n",
    "<h3>References</h3>\n",
    "\n",
    "1. Guangyuan Gao, Bayesian Claims Reserving Methods in Non-life Insurance with Stan. An Introduction, Springer, 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pystan as ps\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "schools_code = \"\"\"\n",
    "data {\n",
    "    int<lower=0> J; // number of schools\n",
    "    real y[J]; // estimated treatment effects\n",
    "    real<lower=0> sigma[J]; // s.e. of effect estimates\n",
    "}\n",
    "parameters {\n",
    "    real mu;\n",
    "    real<lower=0> tau;\n",
    "    real eta[J];\n",
    "}\n",
    "transformed parameters {\n",
    "    real theta[J];\n",
    "    for (j in 1:J)\n",
    "    theta[j] <- mu + tau * eta[j];\n",
    "}\n",
    "model {\n",
    "    eta ~ normal(0, 1);\n",
    "    y ~ normal(theta, sigma);\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "schools_dat = {'J': 8,\n",
    "               'y': [28,  8, -3,  7, -1,  1, 18, 12],\n",
    "               'sigma': [15, 10, 16, 11,  9, 11, 10, 18]}\n",
    "\n",
    "fit = ps.stan(model_code=schools_code, data=schools_dat,\n",
    "                  iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus = fit.extract()['mu']\n",
    "pl.hist(mus, color = '#bbbbee')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 27.1 Introduction</h2>\n",
    "\n",
    "In this section, we review the model diagnostic tools including posterior predictive\n",
    "checking and residual plots. We also discuss the model selection criteria including\n",
    "several information criteria and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 27.2 Posterior Predictive Checking</h2>\n",
    "\n",
    "In the Bayesian framework, ideally we want to split the data into a training set and a testing set and do the posterior predictive checking on the testing data set. \n",
    "\n",
    "\n",
    "Alternatively, we can choose a test statistic whose predictive distribution does not depend on unknown parameters in the model but primarily on the assumption being checked. \n",
    "\n",
    "\n",
    "Then there is no need to have a separate testing data set. Nevertheless, when the same data are used for both fitting and checking the model, this needs to be carried out with caution, as the\n",
    "procedure can be conservative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 27.3 Predictive distribution</h2>\n",
    "\n",
    "The predictive distribution is the distribution of future observations given the\n",
    "current sample. \n",
    "\n",
    "Suppose that $y_{n+1}$ is a future observation\n",
    "independent of the observed data $\\boldsymbol{y}$, given the\n",
    "underlying $\\boldsymbol{\\theta}$. Then, the predictive distribution\n",
    "for $y_{n+1}$ is given by\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "p(y_{n+1}|\\boldsymbol{y}).\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "It can be noted that\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "p(y_{n+1}|\\boldsymbol{y})&=\\int\n",
    "p(y_{n+1},\\boldsymbol{\\theta}|\\boldsymbol{y})d\\boldsymbol{\\theta}\\\\\n",
    "&= \\int\n",
    "f(y_{n+1}|\\boldsymbol{\\theta},\\boldsymbol{y})p(\\boldsymbol{\\theta}|\\boldsymbol{y})d\\boldsymbol{\\theta}\\\\\n",
    "&=\\int\n",
    "f(y_{n+1}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta}|\\boldsymbol{y})d\\boldsymbol{\\theta}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Since\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "p(y_{n+1}|\\boldsymbol{y}) = \\int\n",
    "f(y_{n+1}|\\boldsymbol{\\theta})p(\\boldsymbol{\\theta}|\\boldsymbol{y})d\\boldsymbol{\\theta},\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "predictive values can be obtained inside the MCMC algorithm.  Suppose that in the step $m$ after convergence the sample of\n",
    "$\\boldsymbol{\\theta}$ is $\\boldsymbol{\\theta}^{(m)}$. Then, a\n",
    "predictive value can be drawn from the density\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "f(y|\\boldsymbol{\\theta}^{(m)})\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 27.4 Residuals, Deviance and Deviance Residuals</h2>\n",
    "\n",
    "In the Bayesian framework, we can generate a set of residuals for one realization of\n",
    "posterior parameters. So there are four choices of residuals:\n",
    "1. Choose the posterior mean of parameters and find one set of residuals.\n",
    "2. Randomly choose a realization of parameters and find one set of the residuals.\n",
    "3. Get the posterior mean of residuals.\n",
    "4. Get the posterior distribution of residuals.\n",
    "\n",
    "In the following, we will review Pearson residuals, deviance and deviance residuals.\n",
    "A Pearson residual is defined as\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "r_i(\\theta)= \\frac{ y_i -\n",
    "\\mathbb{E}(Y_i|\\theta)}{\\sqrt{Var(Y_i|\\theta)}}, \\quad\n",
    "i=1,\\cdots,n\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "The **deviance** is defined as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "D(\\theta) := −2 \\log p(y|\\theta) = −2\\sum_{i=1}^n \\log p (yi |\\theta) ,\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "and the contribution of each data point to the deviance is $D_i(\\theta) = −2 \\log p (yi |\\theta)$. We will define and use $D(\\hat{\\theta})$ and $\\widehat{D(\\theta)}$ in the next section.\n",
    "\n",
    "The deviance residuals are based on a standardized or “saturated” version of the\n",
    "deviance, defined as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "D_S(\\theta) := −2 \\sum_{i=1}^n \\log p (y_i |\\theta) + 2 \\sum_{i=1}^n \\log p (yi |\\hat{\\theta}_S(y_i),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "where $\\hat{\\theta}_S(y_i)$ are appropriate “saturated” estimates, e.g., we set $\\hat{\\theta}_S(y)=y$. \n",
    "\n",
    "The contribution of each data point to the standardized deviance is\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "D_{S_i}(\\theta) := −2  \\log p (y_i |\\theta) + 2  \\log p (yi |\\hat{\\theta}_S(y_i),\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The deviance residual is defined as\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "dr_i := sign_i \\sqrt{D_{S_i}(\\theta)},\n",
    "\\end{equation}\n",
    "$$\n",
    "where $sign_i$ is the sign of $y_i − \\mathbb{E}(y_i|\\theta)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 27.5 Three error structures for stack-loss data</h2>\n",
    "\n",
    "Birkes and Dodge (1993) apply different regression models to the much-analysed stack-loss data of Brownlee (1965). This features 21 daily responses of stack loss $y$, the amount of ammonia escaping, with covariates being air flow ($x_1$) , temperature ($x_2$) and acid concentration ($x_3$). \n",
    "\n",
    "We first assume a linear regression on the expectation of $y$, with a variety of different error structures. We assume a linear regression on the expectation of y, i.e.,\n",
    "\n",
    "$$ \\mathbb{E}(y_i) = \\mu_i = b_0 + b_1 z_{1i} + b_2 z_{2i} + b_3 z_{3i} $$\n",
    "\n",
    "\n",
    "   \n",
    "where $z_{ij} = (x_{ij} - \\bar{x}_j ) / \\text{sd}(x_j )$ are covariates standardised to have zero mean and unit variance. $b_1 , b_2 , b_3$ are initially given independent \"noninformative\" priors. \n",
    "\n",
    "We consider three error structures: normal, double exponential\n",
    "and t4, as follows:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "y_i &\\sim \\text{N}(\\mu_i , \\tau^{-1} )\\\\\n",
    "y_i &\\sim \\text{Double exp}( \\mu_i , \\tau^{-1} )\\\\\n",
    "y_i &\\sim \\text{t}_4(\\mu_i , \\tau^{-1} ),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "The deviance residuals of the three models have the following forms respectively:\n",
    "\n",
    "$$ \n",
    "\\begin{align}\n",
    "D_{S_i} &= \\sqrt{\\tau}(y_i-\\mu_i)\\\\\n",
    "D_{S_i} &= sign_i\\sqrt{2\\tau|y_i-\\mu_i|}\\\\\n",
    "D_{S_i} &= sign_i\\sqrt{5\\log\\left( 1 + \\frac{(y_i-\\mu_i)^2}{4} \\right)}.\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 27.5.1 Normal model</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "stacks_data = {'p': 3,\n",
    "'N': 21,\n",
    "'Y': (43, 37, 37, 28, 18, 18, 19, 20, 15, 14, 14, 13, 11, 12, 8, \n",
    "7, 8, 8, 9, 15, 15),\n",
    "'x': np.resize((80, 80, 75, 62, 62, 62, 62, 62, 59, 58, 58, 58, 58, \n",
    "58, 50, 50, 50, 50, 50, 56, 70, 27, 27, 25, 24, 22, 23, 24, 24, \n",
    "23, 18, 18, 17, 18, 19, 18, 18, 19, 19, 20, 20, 20, 89, 88, 90, \n",
    "87, 87, 87, 93, 93, 87, 80, 89, 88, 82, 93, 89, 86, 72, 79, 80, \n",
    "82, 91), (21, 3))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystan\n",
    "%load_ext stanmagic\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stan -f normal_stack_loss_reg.stan\n",
    "// Linear Model with normal Errors\n",
    "\n",
    "data {\n",
    "  int<lower=0> N;  // number of observations\n",
    "  int<lower=0> p;  // number of explained variables\n",
    "  real Y[N];       // observations\n",
    "  matrix[N,p] x;   // design matrix\n",
    "} \n",
    "\n",
    "// to standardize the x's \n",
    "transformed data {\n",
    "  real z[N,p];\n",
    "  real mean_x[p];\n",
    "  real sd_x[p];\n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] <- mean(col(x,j)); \n",
    "    sd_x[j] <- sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] <- (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta0; \n",
    "  real beta[p]; \n",
    "  real<lower=0> sigma; \n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> tau;\n",
    "  real mu[N];\n",
    "  tau <-1/sigma;\n",
    "  for (n in 1:N)\n",
    "    mu[n] <- beta0 + beta[1] * z[n, 1] + beta[2] * z[n, 2] + beta[3] * z[n, 3];\n",
    "}\n",
    "\n",
    "model {\n",
    "  beta0 ~ normal(0, 5); \n",
    "  beta ~ normal(0, 5);\n",
    "  sigma ~ cauchy(0, 2);\n",
    "  for (n in 1:N) \n",
    "    //Y[n] ~ double_exponential(mu[n], sigma); //try you\n",
    "    //Y[n] ~ student_t(4, mu[n], sigma); //try you\n",
    "    Y[n] ~ normal(mu[n], sigma); \n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  real b0;\n",
    "  real b[p];\n",
    "  real residual[N]; // Pearson residual\n",
    "  real outlier[N];  // test for outlier\n",
    "  real resi_dev[N]; // deviance \n",
    "  real y_rep[N];\n",
    "  real pval:\n",
    "\n",
    "  for (j in 1:p)\n",
    "    b[j] <- beta[j] / sd_x[j];\n",
    "  b0 <- beta0 - b[1] * mean_x[1] - b[2] * mean_x[2] - b[3] * mean_x[3];\n",
    "\n",
    "  for (i in 1:N){\n",
    "    residual[i] = (Y[i] - mu[i]) / sigma;\n",
    "    outlier[i] = step(fabs((Y[i] - mu[i]) / sigma) - 2.5);\n",
    "    resi_dev[i] = \\sqrt(tau)*(Y[i] - mu[i]);\n",
    "    y_rep[i] = normal_rng(mu[i],sigma);\n",
    " }\n",
    " \n",
    "    pval = step(sum(normal_lpdf(Y,mu,sigma))-sum(normal_lpdf(y_rep,mu,sigma)));\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_stan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_stack_loss_reg = pystan.StanModel(file=_stan_model.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_stack_loss_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_stack_loss_reg_sample = normal_stack_loss_reg.sampling(data=stacks_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_stack_loss_reg_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traces = normal_stack_loss_reg_sample.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head(traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Some other models for the data to explore.</h4>\n",
    "\n",
    "Please review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stacks_lasso = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> p;\n",
    "  real Y[N];\n",
    "  matrix[N,p] x;\n",
    "} \n",
    "\n",
    "// to standardize the x's \n",
    "transformed data {\n",
    "  real z[N,p];\n",
    "  real mean_x[p];\n",
    "  real sd_x[p];\n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] <- mean(col(x,j)); \n",
    "    sd_x[j] <- sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] <- (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta0; \n",
    "  real beta[p]; \n",
    "  real<lower=0> sigmasq; \n",
    "  real<lower=0> phi;\n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> sigma;\n",
    "  real mu[N];\n",
    "\n",
    "  sigma <- sqrt(2) * sigmasq;\n",
    "  for (n in 1:N)\n",
    "    mu[n] <- beta0 + beta[1] * z[n, 1] + beta[2] * z[n, 2] + beta[3] * z[n, 3];\n",
    "}\n",
    "\n",
    "model {\n",
    "  beta0 ~ normal(0, 316); \n",
    "  phi ~ gamma(0.01, 0.01);\n",
    "  beta ~ normal(0, sqrt(phi));\n",
    "  sigmasq ~ inv_gamma(.001, .001); \n",
    "  for (n in 1:N) \n",
    "    Y[n] ~ double_exponential(mu[n], sigmasq); \n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  real b0;\n",
    "  real b[p];\n",
    "  real outlier_1;\n",
    "  real outlier_3;\n",
    "  real outlier_4;\n",
    "  real outlier_21;\n",
    "\n",
    "  for (j in 1:p)\n",
    "    b[j] <- beta[j] / sd_x[j];\n",
    "  b0 <- beta0 - b[1] * mean_x[1] - b[2] * mean_x[2] - b[3] * mean_x[3];\n",
    "\n",
    "  outlier_1  <- step(fabs((Y[1] - mu[1]) / sigma) - 2.5);\n",
    "  outlier_3  <- step(fabs((Y[3] - mu[3]) / sigma) - 2.5);\n",
    "  outlier_4  <- step(fabs((Y[4] - mu[4]) / sigma) - 2.5);\n",
    "  outlier_21 <- step(fabs((Y[21] - mu[21]) / sigma) - 2.5);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stacks_init = {'beta0': 10,\n",
    "'beta': [0, 0, 0],\n",
    "'sigmasq': 10,\n",
    "'phi': 0.316}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fit_lasso = ps.stan(model_code=stacks_lasso, data=stacks_data, \n",
    "                  iter=1000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sb\n",
    "\n",
    "traces = fit_lasso.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "betas = pd.DataFrame(traces['beta'], columns=['beta1','beta2','beta3']).stack().reset_index()\n",
    "betas.columns = 'obs', 'parameter', 'value'\n",
    "g = sb.FacetGrid(betas, col='parameter')\n",
    "g.map(pl.hist, 'value', color=\"steelblue\",lw=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stacks_ridge = '''\n",
    "data {\n",
    "  int<lower=0> N;\n",
    "  int<lower=0> p;\n",
    "  real Y[N];\n",
    "  matrix[N,p] x;\n",
    "} \n",
    "\n",
    "// to standardize the x's \n",
    "transformed data {\n",
    "  matrix[N,p] z;\n",
    "  row_vector[p] mean_x;\n",
    "  real sd_x[p];\n",
    "  real d;\n",
    "\n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] <- mean(col(x,j)); \n",
    "    sd_x[j] <- sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] <- (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "  d <- 4; // degrees of freedom for t\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta0; \n",
    "  vector[p] beta;\n",
    "  real<lower=0> sigmasq; \n",
    "  real<lower=0> phi;\n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "  real<lower=0> sigma;\n",
    "  vector[N] mu;\n",
    "\n",
    "  sigma <- sqrt(d * sigmasq / (d-2)); // t errors on d degrees of freedom\n",
    "  mu <- beta0 + z * beta; \n",
    "}\n",
    "\n",
    "model {\n",
    "  beta0 ~ normal(0, 316); \n",
    "  phi ~ gamma(0.01, 0.01);\n",
    "  beta ~ normal(0, sqrt(phi));\n",
    "  sigmasq ~ inv_gamma(.001, .001); \n",
    "  Y ~ student_t(d, mu, sqrt(sigmasq));\n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  real b0;\n",
    "  vector[p] b;\n",
    "  real outlier_1;\n",
    "  real outlier_3;\n",
    "  real outlier_4;\n",
    "  real outlier_21;\n",
    "\n",
    "  for (j in 1:p)\n",
    "    b[j] <- beta[j] / sd_x[j];\n",
    "  b0 <- beta0 - mean_x * b;\n",
    "\n",
    "  outlier_1  <- step(fabs((Y[3] - mu[3]) / sigma) - 2.5);\n",
    "  outlier_3  <- step(fabs((Y[3] - mu[3]) / sigma) - 2.5);\n",
    "  outlier_4  <- step(fabs((Y[4] - mu[4]) / sigma) - 2.5);\n",
    "  outlier_21 <- step(fabs((Y[21] - mu[21]) / sigma) - 2.5);\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fit_ridge = ps.stan(model_code=stacks_ridge, data=stacks_data, init=stacks_init,\n",
    "                  iter=10000, chains=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ridge_traces = fit_ridge.extract(permuted=True)\n",
    "\n",
    "ridge_betas = pd.DataFrame(ridge_traces['beta'], columns=['beta1','beta2','beta3']).stack().reset_index()\n",
    "ridge_betas.columns = 'obs', 'parameter', 'value'\n",
    "g = sb.FacetGrid(ridge_betas, col='parameter')\n",
    "g.map(pl.hist, 'value', color=\"steelblue\",lw=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pl.plot(ridge_traces['beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "basket_code = '''\n",
    "data {\n",
    "    int<lower=0> K;\n",
    "    int<lower=0> y[K];\n",
    "    int<lower=0> N[K];\n",
    "}\n",
    "parameters {\n",
    "    real theta[K];\n",
    "    real mu;\n",
    "    real<lower=0> s2;\n",
    "}\n",
    "transformed parameters {\n",
    "    real<lower=0, upper=1> p[K];\n",
    "    for (i in 1:K)\n",
    "        p[i] <- inv_logit(theta[i])\n",
    "}\n",
    "model {\n",
    "    mu ~ normal(-1.34, 100)\n",
    "    s2 ~ inv_gamma(0.00005, 0.000005)\n",
    "    for (i in 1:K)\n",
    "        theta[i] ~ normal(mu, sqrt(s2))\n",
    "        y[i] ~ binomial(n[i], p[i])\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "basket_indep_code = '''\n",
    "data {\n",
    "    int<lower=0> K;\n",
    "    int<lower=0> y[K];\n",
    "    int<lower=0> N[K];\n",
    "}\n",
    "parameters {\n",
    "    real theta[K];\n",
    "}\n",
    "transformed parameters {\n",
    "    real<lower=0, upper=1> p[K];\n",
    "    for (i in 1:K)\n",
    "        p[i] <- inv_logit(theta[i])\n",
    "}\n",
    "model {\n",
    "    for (i in 1:K)\n",
    "        theta[i] ~ normal(-1.34, 100)\n",
    "        y[i] ~ binomial(n[i], p[i])\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Bayesian Model selection</h2>\n",
    "\n",
    "The model selection problem is a trade-off between a simple model and good fitting.\n",
    "\n",
    "Ideally, we want to choose the simplest model with best fitting. \n",
    "\n",
    "However good fitting models tend to be more complicated while simpler models tend to be underfit.\n",
    "\n",
    "The model selection methods used in frequentist statistics are typically cross-validation\n",
    "and information criteria, which are the modified residual sum of squares with respect\n",
    "to the model complexity and overfitting.\n",
    "\n",
    "\n",
    "Cross-validation measures the fit of a model on the testing data set, which is not\n",
    "used to fit the model, while the information criteria adjust the measure of fit on the\n",
    "training data set by adding a penalty for model complexity.\n",
    "\n",
    "\n",
    "<h3>The Predictive Accuracy of a Model</h3>\n",
    "\n",
    "In the Bayesian framework, the fit of a model is sometimes called the predictive\n",
    "accuracy of a model (Gelman et al. 2014). We measure the predictive accuracy of\n",
    "a model to a data set $y'$ by log point wise predictive density (**lppd**), calculated as\n",
    "follows:\n",
    "\n",
    "$$\n",
    "lppd:= \\log \\prod_{i=1}^{n'} \\mathbb{E}_{\\theta|y} p(y'|\\theta) = \\sum_{i=1}^{n'} \\log (\\mathbb{E}_{\\theta|y} p(y'|\\theta)) = \\sum_{i=1}^{n'} \\log \\left( \\int p(y'|\\theta) p(\\theta|y)d\\theta \\right).\n",
    "$$\n",
    "\n",
    "Ideally, $y'$ should not be used to fit the model. If we choose $y' = y$, we get the\n",
    "within-sample lppd (denoted by $lppd_{train}$), which is typically larger than the out-ofsample\n",
    "lppd (denoted by $lppd_{test}$). \n",
    "\n",
    "\n",
    "To compute **lppd** in practice, we can evaluate the expectation using draws from the posterior distribution $p(θ|y)$, which we label as $\\theta^{(t)}, t = 1, \\ldots, T$ . The computed lppd is defined as follows:\n",
    " \n",
    "\n",
    "$$\n",
    "\\text{computed } lppd:= \\sum_{i=1}^{n} \\log\\left( \\frac{1}{T} \\sum_{t=1}^{T} p(y'|\\theta^{(t)})\\right).\n",
    "$$\n",
    "\n",
    "<h3>Cross Validation</h3>\n",
    "\n",
    "In Bayesian cross-validation, the data are repeatedly partitioned into a training set\n",
    "$y_{train}$ and a testing set $y_{test}$. \n",
    "\n",
    "\n",
    "For simplicity, we restrict our attention to leave-one-out cross-validation (LOO-CV), where ytest only contains a data point. The Bayesian LOO-CV estimate of out-of-sample lppd is defined as follows:\n",
    "\n",
    "$$\n",
    "lppd_{loo-cv} := \\sum_{i=1}^{n} \\log \\left( p (y_i |\\theta) p (\\theta|y_{−i} ) d\\theta\\right).\n",
    "$$\n",
    "\n",
    "where $y_{−i}$ is the data set without the $i$-th point. The $lppd_{loo-cv}$ can be computed as\n",
    "\n",
    "$$\n",
    "\\text{computed } lppd_{loo-cv} = \\sum_{i=1}^{n} \\log  \\left( \\sum_{t=1}^{T} p(y'|\\theta^{(it)}) \\right),\n",
    "$$\n",
    "\n",
    "where $\\theta^{(it)}, t = 1, \\ldots , T$ are the simulations from the posterior distribution $p(\\theta|y_{-i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Deviance Information Criterion DIC</h3>\n",
    "\n",
    "Before describing the DIC, we review another two information criteria employed in\n",
    "frequentist statistics. The Akaike information criterion (AIC) by Akaike (1973) is\n",
    "defined as\n",
    "\n",
    "$$\n",
    "AIC:= − 2\\sum_{i=1}^{n} \\log p (y_i |\\theta_{MLE}) + 2p.\n",
    "$$\n",
    "\n",
    "\n",
    "The Bayesian information criterion (BIC) by Schwarz (1978) is defined as\n",
    "\n",
    "\n",
    "$$\n",
    "AIC:= − 2\\sum_{i=1}^{n} \\log p (y_i |\\theta_{MLE}) + p\\log n\n",
    "$$,\n",
    "\n",
    "where $p$ is the number of parameters. The first common term $− 2\\sum_{i=1}^{n} \\log p (y_i |\\theta_{MLE})$\n",
    "measures the discrepancy between the fitted model and the data. The second term measures the model complexity.\n",
    "\n",
    "\n",
    "<h4> DIC </h4>\n",
    "\n",
    "In the Bayesian framework, we define a similar quantity to measure the discrepancy,\n",
    "$-2 \\sum_{i=1}^{n} \\log p(y_i | \\hat{\\theta})$, where $\\hat{\\theta}$ is the posterior mean. Spiegelhalter et al. (2002) proposed a measure of number of effective parameters, which is defined as the difference\n",
    "between the posterior mean of the deviance and the deviance at the posterior means,\n",
    "as follows:\n",
    "\n",
    "$$\n",
    "p_D := \\widehat{D (\\theta)} - D(\\hat{\\theta}) = −2\\mathbb{E}_{\\theta|y} \\left(\\sum_{i=1}^{n} \\log p (y_i |\\theta)\\right) + 2 \\sum_{i=1}^{n} \\log p(y_i|\\hat{\\theta}),\n",
    "$$)\n",
    "\n",
    "where $D$ is the deviance defined above.\n",
    "\n",
    "\n",
    "Furthermore, they proposed a deviance information criterion (DIC), defined as\n",
    "the deviance at the posterior means plus twice the effective number of parameters,\n",
    "to give\n",
    "\n",
    "$$\n",
    "DIC := D( \\hat{\\theta}) + 2p_D.\n",
    "$$\n",
    "\n",
    "DIC is viewed as a Bayesian analogue of AIC. We prefer the model with smaller\n",
    "DIC. \n",
    "Note that DIC and $p_D$ are sensitive to the level of a hierarchical model. They are appropriate when we are interested in the parameters directly related to the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Watanabe-Akaike or widely available information criterion (WAIC)</h3>\n",
    "\n",
    "Watanabe (2010) proposed another measure of number of effective parameters as follows:\n",
    "\n",
    "$$\n",
    "p_{WAIC} := \\widehat{D(\\theta)} + 2lppd_{train} = −2\\mathbb{E}_{\\theta|y} \\left(\\sum_{i=1}^{n} \\log p (y_i |\\theta) \\right) + 2 \\sum_{i=1} ^{n} \\log \\left( \\mathbb{E}_{\\theta|y} p (y_i |\\theta)\\right),\n",
    "$$\n",
    "\n",
    "where $−2lppd_{train}$ plays a role as $D(\\hat{\\theta})$ as in $p_D$. As with AIC and DIC, the Watanabe-\n",
    "Akaike information criterion (WAIC) is defined as\n",
    "\n",
    "$$\n",
    "WAIC:= − 2lppd_{train} + 2p_{WAIC}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Leave-One-Out Information Criterion (LOOIC)</h3>\n",
    "\n",
    "Different from the definition of number of effective parameters in AIC, DIC, and\n",
    "WAIC, we define\n",
    "\n",
    "$$\n",
    "p_{loo} := lppd_{train} − lppd_{loo-cv},\n",
    "$$\n",
    "\n",
    "where $lppd_{loo-cv}$ comes from above. The leave-one-out information criterion (LOOIC) is defined as\n",
    "\n",
    "$$\n",
    "LOOIC:= − 2lppd_{train} + 2p_{loo} = −2lppd_{loo-cv},\n",
    "$$\n",
    "\n",
    "which is reasonable since $lppd_{loo-cv}$ already penalizes the overfitting (or equivalently\n",
    "the model complexity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
