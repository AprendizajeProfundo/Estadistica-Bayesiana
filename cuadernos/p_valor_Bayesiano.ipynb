{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-valor Bayesiano\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2. Guangyuan Gao, \"Bayesian Claims Reserving Methods in Non-life Insurance with Stan. An Introduction\", Springer, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "En esta lección revisamos el procedimiento de validación cruzada para evaluar el ajuste del modelo a cada dato, en situaciones de pocos datos observados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de réplicas de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos un modelo bayesiano con parámetros $\\boldsymbol{\\theta}$ y datos continuos $\\mathbf{y}$. Vamos a considerar $\\boldsymbol{\\theta}$  con réplicas potenciales de los datos $\\mathbf{y}^{rep}$ definidas en la misma forma como teóricamente se produjeron los datos.\n",
    "\n",
    "En la práctica esto significa que si $p(\\boldsymbol{\\theta}|y)$ es la posterior de $\\boldsymbol{\\theta}$, entonces definimos replicas de la siguiente forma:  \n",
    "\n",
    "1. Generamos una muestra $\\boldsymbol{\\theta}^{(1)}, \\ldots, \\boldsymbol{\\theta}^{(n)}$, a partir de la posterior $p(\\boldsymbol{\\theta}|y)$.\n",
    "\n",
    "2. Para cada muestra $\\boldsymbol{\\theta}^{(k)}$ se obtiene una muestra (replica) de los datos $\\mathbf{y}^{rep (k)}$ a partir de de la verosimilitud $f(y|\\boldsymbol{\\theta}^{(k)})$, exáctamente como se produjeron los datos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo. Modelo de Regresión Normal homocedástico $\\mathcal{N}(\\mu_i,\\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si este es el verdadero que produjo los datos, lo que ocurrió es que \n",
    "\n",
    "### Generación de los datos\n",
    "\n",
    "Este es el proceso que teóricamente ocurrió para generar los datos.\n",
    "\n",
    "1. $\\boldsymbol{\\theta}$ fué generado a partir de una distribución (desconocido) $P(\\boldsymbol{\\theta})$. En este ejemplo se tiene que  $\\boldsymbol{\\theta} = (\\alpha,\\boldsymbol{\\beta},\\sigma)'$.\n",
    "\n",
    "2. Cada observación $y_i$ tienen distribución $\\mathcal{N}(\\mu_i,\\sigma^2)$, en donde $\\mu_i = \\alpha + \\mathbf{x}_i'\\boldsymbol{\\beta}$. Así que el dato observado $y_i$ es obtenido como una muestra aleatoria de $\\mathcal{N}(\\mu_i,\\sigma^2)$. \n",
    "\n",
    "\n",
    "### Generación de las réplicas\n",
    "\n",
    "Nosotros construimos la posterior $p(\\boldsymbol{\\theta}|y)$. Esta es nuestra aproximación de la distribución desconocida $P(\\boldsymbol{\\theta})$. Entonces las réplicas son obtenidas como sigue.\n",
    "\n",
    "1. Se obtiene una muestra $\\boldsymbol{\\theta}^{(1)}, \\ldots, \\boldsymbol{\\theta}^{(n)}$, a partir de la posterior $p(\\boldsymbol{\\theta}|y)$.  Aquí $\\boldsymbol{\\theta}^{(k)} =(\\alpha^{(k)}, \\boldsymbol{\\beta}^{(k)}, \\sigma^{(k)})'$.\n",
    "\n",
    "2. A partir de cada muestra posterior $(\\alpha^{(k)}, \\boldsymbol{\\beta}^{(k)}, \\sigma^{(k)})'$ se calcula $\\mu_i^{(k)}= \\alpha^{(k)} +\\mathbf{x}_i'\\boldsymbol{\\beta}^{(k)} $. La réplica de la observación $y_i$ en este caso se obtiene como una muestra de la distribución $\\mathcal{N}(\\mu_i^{(k)},  \\sigma^{(k)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística de discrepancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La técnica más extendida para evaluar los modelos es la introducción de una estadística de discrepancia (del modelo con respecto a los datos).\n",
    "\n",
    "Supongamos que $\\mathbf{y}$ representa un conjunto de observaciones. Puede ser una única observación o el vector completo de observaciones. La estadística de discrepancia se denotará por $T(\\mathbf{y})$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de estadísticas de discrepancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos construido antes estadisticas de discrepancia. Completamos aquí dos de ellas, las cuales pueden ser aplicadas para observaciones individuales (para evaluar) el ajuste del modelo a observaciones individuales y también para evaluar el ajuste global del modelos a los datos.\n",
    "\n",
    "Estes tipo de estadísticas que pueden usarse tanto para observaciones individuales para para todo el conjunto de datos usualmente reciben el nombre de estadísticas *omnibus*.\n",
    "\n",
    "Supongamos $\\mathbf{y}=(y_1,\\ldots,y_n)'$ , $E[y_i]=\\mu_i$ y $Var[y_i] = \\sigma_i^2$. En lo que sigue vamos a suponer que $\\boldsymbol{\\theta}$ es el valor verdadero del parámetro, o una estimación muy precisa del mismo.\n",
    "\n",
    "\n",
    "### Residuales de Pearson estandarizados\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(y_i|\\boldsymbol{\\theta}) &= \\frac{(y_i-\\mu_i)^2}{\\sigma_i^2}\\\\\n",
    "T(\\mathbf{y}|\\boldsymbol{\\theta}) &= \\sum_{i=1}^n \\frac{(y_i-\\mu_i)^2}{\\sigma_i^2}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "###   Discrepancia Deviance \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(y_i|\\boldsymbol{\\theta}) &= -2 \\log f(y_i|\\boldsymbol{\\theta})\\\\ \n",
    "T(\\mathbf{y}|\\boldsymbol{\\theta})&=-2 \\sum_{i=1}^n \\log f(y_i|\\boldsymbol{\\theta})\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribución de $P(X<Y)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que $X$ y $Y$ son variables aleatorias contínuas con la misma ditribución $F$. El teorema de transformación integral de la probabilidad establece que $F(X)$ y $F(Y)$ tienen distribución Uniforme $\\mathcal{U}[0,1]$.\n",
    "\n",
    "En consecuencia como $P(X<Y)= F(Y)$, se concluye que $P(X<Y)  \\sim \\mathcal{U}[0,1]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# P-valor Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos  que se comprobará el modelo basado en el valor $p$ de alguna estadística de prueba $T(\\mathbf{y})$.\n",
    "\n",
    "En el caso especial en el que $\\boldsymbol{\\theta}$ es conocido (o se estima con una precisión muy alta)\n",
    "o en el que $T(\\mathbf{y})$ es auxiliar (o casi), el **$p$-valor  Bayesiano** (predictivo posterior) \n",
    "es dado por $Pr (T(\\mathbf{y}^{rep})> T(\\mathbf{y}) | \\mathbf{y})$  y tiene una distribución que es uniforme (o aproximadamente uniforme) si el modelo es verdadero. \n",
    "\n",
    "En estas condiciones, en el 10% del tiempo, se producen valores de $p$ inferiores a 0.1. Los valores de $p$ inferiores a 0,05 ocurren el 5% del tiempo, y así sucesivamente.\n",
    "\n",
    "\n",
    "Más generalmente, cuando la incertidumbre posterior en $\\boldsymbol{\\theta}$ se propaga a la distribución de $T(\\mathbf{y} | \\boldsymbol{\\theta})$, la distribución del valor $p$, si el modelo es verdadero, está más concentrada cerca de la mitad del rango: es más probable que el valor $p$  esté cerca de 0.5 que cerca de 0 o 1. \n",
    "\n",
    "Para ser más precisos, la distribución de muestreo del valor $p$ se ha demostrado que es \"estocásticamente menos variable\" que el uniforme)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluación de modelos mediante el p-valor Bayesiano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En lo que sigue vamos a suponer que se dispone de una cantidad de datos suficiente para dividirlos en dos grupos. No hay un acuerdo sobre que significa número sufiente de datos. Aquí vamos a suponer que tenemos digamos $n=100$ datos. Vamos a utilizar un subconjunto de datos, digamos el 80% para ajustar el modelo y el 20% para evaluarlo.\n",
    "\n",
    "Cuando no haya suficientes datos, digamos mnos de 100, se puede utilizar el procedimiento de [validación cruzada](./Validacion_Cruzada.ipynb) que encuentra en esa lección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos entonces que $\\mathbf{z}$ es el conjunto de datos que se usará para ajustar el modelo, y que $\\mathbf{x}$ es el conjunto de datos para validación del modelo. Se tiene entonces que los datos son  $\\mathbf{y}= (\\mathbf{z}'$,$\\mathbf{x}')'$.\n",
    "\n",
    "Supongamos que $p(\\boldsymbol{\\theta}|\\mathbf{z})$ es la distribución posterior obtenida a partir de $\\mathbf{z}$.\n",
    "\n",
    "Usaremos la estadística\n",
    "\n",
    "$$\n",
    "g(\\mathbf{x}^{rep}, \\mathbf{x},\\mathbf{z},\\boldsymbol{\\theta}) = P[T(\\mathbf{x}^{rep}|\\boldsymbol{\\theta})>T(\\mathbf{x}|\\boldsymbol{\\theta})| \\mathbf{z}]\n",
    "$$\n",
    "\n",
    "\n",
    "Para decidir, se procede de la siguiente manera. Si la media de la estadística está alrededor de 0.5 (que es la media de la distribución $\\mathcal{U}(0,1)$), se tiene evidencia que el modelo ajusta bien a los datos. Valores aceptables pueden ser entre 0.25 y 0.75. \n",
    "\n",
    "Si la media tiende a ser cercana a cero o a uno, es evidencia que el modelo no ajusta a los datos. Digamos valores menores a 0.1 o mayores a 0.9.  \n",
    "\n",
    "Para el resto valores el modelo puede ser factible muy cuidadosamente y es necesario tratar de mejorarlo, ya sea con más datos o con otra distribución o ambos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algortimo para calcular el $p$-valor Bayesiano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Obtenga una muestra $\\boldsymbol{\\theta}^{(k)}$ de la posterior $p(\\boldsymbol{\\theta}|\\mathbf{z})$.\n",
    "2. Obtenga una réplica $\\mathbf{x}^{(k)}$ a partir de la verosimiitud $f(\\mathbf{x}|\\boldsymbol{\\theta}^{(k)})$, en la misma forma como se obtuvo la muestra $\\mathbf{x}$.\n",
    "4. Calcule las discrepancias $T(\\mathbf{x}^{rep}|\\boldsymbol{\\theta}^{(k)})$ y $T(\\mathbf{x}|\\boldsymbol{\\theta}^{(k)})$.\n",
    "5. Calcule la estadística $1_{\\{T(\\mathbf{x}^{rep}|\\boldsymbol{\\theta}^{(k)})>T(\\mathbf{x}|\\boldsymbol{\\theta}^{(k)})\\}}$\n",
    "6. El $p$-valor Bayesiano es $p =m^{-1} \\sum_k 1_{\\{T(\\mathbf{x}^{rep}|\\boldsymbol{\\theta}^{(k)})>T(\\mathbf{x}|\\boldsymbol{\\theta}^{(k)})\\}}$, en donde $m$ es el número de muestras de la estadística $1_{\\{T(\\mathbf{x}^{rep}|\\boldsymbol{\\theta}^{(k)})>T(\\mathbf{x}|\\boldsymbol{\\theta}^{(k)})\\}}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ridge_traces = fit_ridge.extract(permuted=True)\n",
    "\n",
    "ridge_betas = pd.DataFrame(ridge_traces['beta'], columns=['beta1','beta2','beta3']).stack().reset_index()\n",
    "ridge_betas.columns = 'obs', 'parameter', 'value'\n",
    "g = sb.FacetGrid(ridge_betas, col='parameter')\n",
    "g.map(pl.hist, 'value', color=\"steelblue\",lw=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
