{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curso de Estadística Bayesiana\n",
    "\n",
    "## Examen 1 - Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profesor\n",
    "\n",
    "### Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2. De Paula Gilberto, [\"MODELOS DE REGRESSÃO com apoio computacional, ](https://www.ime.usp.br/~giapaula/texto_2013.pdf), Instituto de Matemática e Estatística  Universidade de São  Paulo\n",
    "3.  [\"Stan User's Guide. Version 2.22\", Stan Development Team, 2020.](https://mc-stan.org/users/documentation/)\n",
    "4. Kumar, Ravin and Carroll, Colin and Hartikainen, Ari and Martin, Osvaldo A., [ArviZ a unified library for exploratory analysis of Bayesian models in Python](https://arviz-devs.github.io/arviz/), [The Journal of Open Source Software], 2019.\n",
    "5. Richard McElreath, [\"Statistical Rethinking, A Bayesian Course with examples in R and Stan\"](http://xcelab.net/rmpubs/rethinking/Statistical_Rethinking_sample.pdf), version compilada en noviembre 9 de 2015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "   \n",
    "Bienvenidas y bienvenidos  al primer parcial. Recuerden que este parcial es para aprender principalmente y para consolidar sus conocimientos.\n",
    "\n",
    "Pueden trabajar en grupo, máximo dos personas. Preparen su informe en un cuaderno de Jupyter Lab. Sus códigos debe escribirlos en Pystan y Python.\n",
    "Suba la  solución de su examen antes de la media noche (12.00 de la noche) del día 03 de mayo de 2020 a las 11.59. Favor enviar el enlace de su drive, a las siguientes direcciones:  ammontenegrod@unal.edu.co, ammontenegrod@gmail.com, con permiso para para lectura.\n",
    "\n",
    "Puede modificar el archivo cuantas veces desee, luego de esa fecha. Sin embargo a partir de esa fecha el profesor queda en libertad de revisar y emitir una calificación preliminar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisión de Conceptos (20%)\n",
    "\n",
    "Haga una breve disertación en sus propias palabras de lo estudiado hast ahora en el curso incluyendo los siguientes conceptos:\n",
    "\n",
    "1. Distribución de los parámetros.\n",
    "2. Distribución conjunta de parámetros y observaciones.\n",
    "3. Distribución posterior.\n",
    "4. Distribución predictiva.\n",
    "\n",
    "Puede apoyarse en la bibliografía propuesta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Respuesta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementos Básicos de Estadística Bayesiana\n",
    "\n",
    "En la estadística Bayesiana se asume que tanto los parámetros (que llamaremos simplemente parámetro) como los datos son generados por distribuciones. Denotaremos por $\\mathbf{\\theta}$ al parámetro y por $\\mathbf{x}$ a las observaciones. Por facilidad asumiremos en este documento que $\\mathbf{\\theta}=(\\theta_1,\\ldots,\\theta_p)^t$ y que $\\mathbf{x}$ es una matrix aleatoria de tamaño $m\\times n $, en donde cada fila corresponde a una observación denotada por $\\mathbf{x}_i$. \n",
    "\n",
    "Adicionalmente asumiremos que las  $\\mathbf{x}_i$ son variables aleatorias condicionalmente independientes con respecto al parámetro, es decir $\\mathbf{x}_i|\\mathbf{\\theta}$ son idependientes. Si $f(\\mathbf{x}_i|\\mathbf{\\theta})$ denota la densidad de $\\mathbf{x}_i$ dado $\\mathbf{\\theta}$, entonces se tiene que\n",
    "\n",
    "$$\n",
    "f(\\mathbf{x}|\\mathbf{\\theta})= \\prod_{i=1}^n f(\\mathbf{x}_i|\\mathbf{\\theta}).\n",
    "$$\n",
    "\n",
    "Se observa entonces que $f(\\mathbf{x}|\\mathbf{\\theta})$ es una función de densidad condicional, la cual se denomina función de verosimilitud o simplemete verosimilitud. Es importante entender que esta definición diferencia a la estadística clásica o frecuentista de la estadística moderna o Bayesiana. En efecto, en la estadística clásica la verosimilitud es simplemente una función del parámetro y los datos (los cuales son conocidos). En la estadística Bayesiana, la verosimiltud es una función de densidad condicional. \n",
    "\n",
    "\n",
    "Estas son cantidades aleatorias que se suponen dependientes. El problema en la estadística Bayesiana es determinar cuál es el valor, digamos $\\mathbf{\\theta}^0$ de  $\\mathbf{\\theta}$ que es más plausible para los datos observados, los cuales denotaremos por $\\mathbf{x}^0$.\n",
    "\n",
    "Por simplicidad se puede pensar que  $\\mathbf{\\theta}$ es una variable latente, es decir,  una variable que no puede observarse directamente, mientras que las observaciones si son observables directactame.\n",
    "\n",
    "Dado que $\\mathbf{\\theta}$ y $\\mathbf{x}$ son objetos aleatorias (vectores y matrices) dependientes, se tiene que la distribución condicional de  $\\mathbf{\\theta}|\\mathbf{x}$ es dada de acuerdo con el teorema de Bayes por\n",
    "\n",
    "$$\n",
    "f(\\mathbf{\\theta}|\\mathbf{x}) = \\frac{f(\\mathbf{x}|\\mathbf{\\theta})p(\\mathbf{\\theta})}{\\int f(\\mathbf{x}|\\mathbf{\\theta})p(\\mathbf{\\theta}) d\\mathbf{\\theta}} = \\frac{f(\\mathbf{x}|\\mathbf{\\theta})p(\\mathbf{\\theta})}{p(\\mathbf{x})}.\n",
    "$$\n",
    "\n",
    "La función de densidad condicional $f(\\mathbf{\\theta}|\\mathbf{x})$ se denomina desnidad posterior o simplemente posterior. En esta expresión $p(\\mathbf{\\theta})$ y $p(\\mathbf{x})$ son las densidades marginales de $\\mathbf{\\theta}$ y $\\mathbf{x}$ respectivamente. La densidad $p(\\mathbf{\\theta})$ es en general desconocida y se denomina densidad a priori y su respectiva distribución se denominará distribución a priori. \n",
    "\n",
    "En el proceso de inferencia es necesario proponer distribuciones  apriori que tengan sentido para el parámetro  $\\mathbf{\\theta}^0$ que se desea estimar.  Por ejemplo, si  $\\mathbf{\\theta}^0$  corresponde a una probabilidad, es necesario proponer una distribución a priori con dominio (soporte) en $[0,1]$, como por ejemplo $U(0,1)$ o de manera más general $\\text{Beta}(a,b)$.\n",
    "\n",
    "\n",
    "Por otro lado, dada  $p(\\mathbf{\\theta})$ la densidad $p(\\mathbf{x})$ puede calcularse, dado que es una integral. No obstante este es justamente uno de los problemas de la estadística Bayesiana dado que la integral es por lo general intratable.\n",
    "\n",
    "Puede observarse que la densidad conjunta de $\\mathbf{\\theta}$ y $\\mathbf{x}$ puede escribirse como\n",
    "\n",
    "$$\n",
    "f(\\mathbf{\\theta}, \\mathbf{x}) = f(\\mathbf{\\theta}| \\mathbf{x})p(\\mathbf{x}) = f(\\mathbf{x}| \\mathbf{\\theta})p(\\mathbf{\\theta}).\n",
    "$$\n",
    "\n",
    "\n",
    "Para terminar este ensayo se introduce el concepto de densidad predictiva. Supóngase que $\\mathbf{y}$ es una observación no incluída en $\\mathbf{x}$. La densidad predictiva es la densidad que predice datos del modelo estadístico en estudio a partir de las observaciones. Técnicamente se define por $f(\\mathbf{y} |\\mathbf{x})$. Se puede entonces deducir que a partir de la independencia condicional  se tiene que \n",
    "$$\n",
    "f(\\mathbf{y} |\\mathbf{x}) = \\int f(\\mathbf{y}|\\mathbf{\\theta}) p(\\mathbf{\\theta}|\\mathbf{x})d\\mathbf{\\theta},\n",
    "$$\n",
    "\n",
    "\n",
    "Por lo que una regla para obtener una observación de $f(\\mathbf{y} |\\mathbf{x}=\\mathbf{x}_0)$ es obtener una muestra $\\mathbf{\\theta}^*$ de la posterior $p(\\mathbf{\\theta}|\\mathbf{x})$ y luego obtener la muestra requerida a partir de $ f(\\mathbf{y}|\\mathbf{\\theta}=\\mathbf{\\theta}^*)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo Beta-Binomial 10%\n",
    "\n",
    "Considere un modelo de observación Binomial. $y\\sim\n",
    "Bin(n, \\pi)$. \n",
    "\n",
    "1. Considere la a priori plana $p(\\pi)\\varpropto 1$. encuentre\n",
    "la distribución a posteriori, y el estimador Bayesiano EAP de\n",
    "$\\pi$.\n",
    "2. Considere la a priori de Jeffreys $p(\\pi)\\varpropto\n",
    "\\left[I(\\pi)\\right]^{1/2}$. Encuentre la distribución a\n",
    "posteriori de $\\pi$ y el estimador Bayesiano EAP de $\\pi$.\n",
    "3. Considere la a priori general $Beta(\\alpha,\\beta)$. Encuentre la distribución a\n",
    "posteriori de $\\pi$, el estimador Bayesiano EAP de $\\pi$ y la varianza de la distribución posterior the  $\\pi$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo general\n",
    "\n",
    "Considere un modelo de observacional Binomial. $y \\sim Bin(n,\\pi)$.\n",
    "\n",
    "\n",
    "- La verosimilitud es dada por\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(y|\\pi)= {n\\choose y} \\pi^{y}(1-\\pi)^{(n-y)}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "- A priori: el modelo con el cual conjuga y de donde se propone que proviene $\\pi$ es un modelo $Beta(\\alpha,\\beta)$ cuya función de densidad es dada por\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\pi)=\\dfrac{1}{B(\\alpha,\\beta)}\\pi^{\\alpha-1}(1-\\pi)^{\\beta-1}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "  Donde $B(\\alpha,\\beta)$ es la función beta.\n",
    "\n",
    "- Posterior\n",
    "\n",
    "$$\n",
    "p(\\pi|y) \\propto \\pi^{y}(1-\\pi)^{(n-y)} \\pi^{\\alpha-1}(1-\\pi)^{\\beta-1} \\propto \\pi^{y+\\alpha-1}(1-\\pi)^{n+y+\\beta-1},\n",
    "$$\n",
    "\n",
    "por lo que $p(\\pi|y) = \\text{Beta}(y+\\alpha, n-y+\\beta)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Esperanza posterior para el caso general: $p(\\pi) = \\text{Beta}(\\alpha,\\beta)$\n",
    "\n",
    "- Para agilizar los cálculos se reparametriza definiendo $(\\mu, M)$ como $\\mu= \\alpha/(\\alpha+\\beta)$, siendo esta la media a priori y se define $M= \\alpha+\\beta$, como una medida de precisón de la apriori. Dado esto, la varianza a priori se define como $\\mu(1-\\mu)/(M+1)$ la cual resulta una función decreciente de $M$. La distribución marginal de $Y$ es llamada *beta-binomial*, y tiene la siguiente forma:\n",
    "$$\n",
    "\\begin{align}\n",
    "  E\\left[\\frac{Y}{n}\\right] &=\\mu\\\\\n",
    " Var\\left[\\frac{Y}{n}\\right] &= \\frac{\\mu(1-\\mu)}{n}\\left[ 1+ \\frac{n-1}{M+1} \\right].\n",
    "\\end{align}\n",
    "$$\n",
    "- Con lo que finalmente la distribución posterior de $\\pi$ es de nuevo una distribución Beta de parámetros $Beta(Y + \\alpha, n − Y + \\beta)$, con:\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat{\\pi}=E\\left[\\pi|Y\\right] &= \\frac{M}{M+n}\\mu + \\frac{n}{M+n}\\left(\\frac{Y}{n}  \\right)\\\\\n",
    " Var\\left[\\pi|Y\\right] &= \\left[\\hat{\\pi}(1-\\hat{\\pi})/(M+n+1)  \\right].\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Este es el caso más general y de aquí se derivan los demás análisis en los literales propuestos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A priori plana: $p(\\pi) \\propto 1$. \n",
    "\n",
    "\n",
    "- Como caso particular de la distribución Beta, cuando $\\alpha=1$ y $\\beta=1$ se vuelve una distribución Uniforme $(0,1)$, de esta manera al hacer los reemplazos llegamos al caso analizado, y así, $\\mu=1/2$ y $M=2$.\n",
    "\n",
    "  Así se hacen los reemplazos respectivos llegando a que la distribución a posteriori viene definida por $Beta(Y + 1, n − Y + 1)$, con el estimador EAP dado por:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat{\\pi}=E\\left[\\pi|Y\\right] &= \\frac{M}{M+n}\\mu + \\frac{n}{M+n}\\left(\\frac{Y}{n}  \\right)\\\\\n",
    "           = \\frac{Y+1}{n+2}\n",
    " \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A priori de Jeffreys: $p(\\pi) \\propto[I(\\pi)]^{1/2}$. \n",
    "\n",
    "Para obtener la a priori de Jeffreys $p_J(\\theta)$ se desagrega la función de verosimilitud de la distribución binomial y se calcula su segunda derivada respecto al parámetro de interés $\\pi$:\n",
    "\n",
    "$$\\begin{align*}\n",
    "l := \\log(p(y | \\pi)) &= y \\log(\\pi) + (n-y) \\log(1-\\pi) + \\text{constante} \\\\\n",
    "\\frac{\\partial l }{\\partial \\pi} &= \\frac{y}{\\pi} - \\frac{n-y}{1-\\pi} \\\\\n",
    "\\frac{\\partial^{2} l }{\\partial \\pi^{2}} &= -\\frac{y}{\\pi^{2}} - \\frac{n-y}{ (1-\\pi)^{2} }\n",
    "\\end{align*}$$\n",
    "\n",
    "Así, la información de Fisher es:\n",
    "\n",
    "$$\\begin{align*}\n",
    "I(\\pi) &= -E\\left(\\frac{\\partial^{2} l }{\\partial \\pi^{2}} | \\pi\\right) \\\\\n",
    "&= \\frac{n\\pi}{\\pi^{2}} + \\frac{n - n \\pi}{(1-\\pi)^{2}} \\\\\n",
    "&= \\frac{n}{\\pi ( 1- \\pi)} \\\\\n",
    "&\\propto \\pi^{-1} (1-\\pi)^{-1}.\n",
    "\\end{align*}$$\n",
    "\n",
    "\n",
    "Y la a priori de Jeffreys queda como:\n",
    "\n",
    "$$\\begin{align*}\n",
    "I(\\pi) &= -E\\left(\\frac{\\partial^{2} l }{\\partial \\pi^{2}} | \\pi\\right) \\\\\n",
    "&= \\frac{n\\pi}{\\theta^{2}} + \\frac{n - n \\pi}{(1-\\pi)^{2}} \\\\\n",
    "&= \\frac{n}{\\pi ( 1- \\pi)} \\\\\n",
    "&\\propto \\pi^{-1} (1-\\pi)^{-1}.\n",
    "\\end{align*}$$\n",
    "\n",
    "Siendo esta una distribución $Beta(1/2,1/2)$. Utilizando el mismo argumento del literal anterior, se hacen los reemplazos respectivos, con lo que la distribución a posterior es una $Beta(Y + 1/2, n − Y + 1/2)$, con el estimador EAP dado por:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "  \\hat{\\pi}=E\\left[\\pi|Y\\right] &= \\frac{M}{M+n}\\mu + \\frac{n}{M+n}\\left(\\frac{Y}{n}  \\right)\\\\\n",
    "           = \\frac{Y+2}{n+1}\n",
    " \\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo para datos asimétricos 35%\n",
    "\n",
    "Los datos de la tabla 1 muestran los resultados de un experimento conducido para evaluar el desempeño de cinco tipos de turbina de alta velocidad para motores de aviación. Fueron considerados 10 motores de cada tipo para el análisis. Verifique que es razonable suponer que cada  medida $T_{ij}, i =1,\\ldots,5, j=1,\\ldots,10$  puede ser modelada como  $T_{ij} \\sim Gamma(\\mu_i,\\phi)$, en donde \n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\mu_i= \\mu + \\beta_i, i =1,\\dots,5\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "|Tipo 1 | Tipo 2 | Tipo 3 | Tipo 4 | Tipo 5|\n",
    "|---|---|---|---|---|\n",
    "|3.03    |   3.19    |    3.46   |    5.88     |     6.43|\n",
    "|5.53    |    4.26   |   5.22    |     6.74    |     9.97|\n",
    "|5.60    |    4.47   |    5.69   |     6.90    |    10.39|\n",
    "|9.30    |    4.53   |    6.54   |     6.98    |    13.55|\n",
    "|9.92    |    4.67   |    9.16   |     7.21    |    14.45|\n",
    "|12.51   |    4.69   |    9.40   |     8.14    |    14.72|\n",
    "|15.21   |    6.79   |   10.71   |     9.80    |    18.39|\n",
    "|16.04   |    9.37   |   12.58   |    12.28    |    20.84|\n",
    "|16.84   |  12.75    |   13.41   |    25.46    |    21.51|\n",
    "\n",
    "*Tabla 1. Tiempo (en millones de ciclos) hasta perder velocidad por tipo de turbina, de 10 10 motores por cada tipo de turbina*\n",
    "\n",
    "Use Stan para obtener una estimación de los parámetros $\\mu, \\beta_i, i=1,\\ldots,5$, y $\\phi$. Haga una discusión detallada de los resultados. Incluya los datos, gráficas y estadísticas que considere necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo Estadístico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Stan la distribución Beta tiene la forma \n",
    "\n",
    "$$\n",
    "\\text{Gamma}(y|a,b) = \\frac{a^{b}}{\\Gamma(a)}{y^{a-1}\\exp(-b y)}\n",
    "$$\n",
    "\n",
    "Si $\\mu$ es la media de la distribución, se tiene que\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mu &= \\frac{a}{b}\\\\\n",
    "\\sigma^2 &= \\frac{a}{b^2} = \\mu\\frac{1}{b}\n",
    "\\end{align}\n",
    "$$\n",
    "Sea $\\phi = \\frac{1}{\\sigma^2}$. Entonces $\\phi$ es el parámetro de precisión de cada grupo de turbinas.\n",
    "\n",
    "Por lo que podemos hacer la reparametrización\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "a &= \\phi\\mu^2 \\\\\n",
    "b &= \\phi\\mu\n",
    "\\end{align}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora bien. Supongamos que la matrix de datos es $y$ de tamaño $N\\times T$, en donde $N=10$ es el numéro de observaciones por tipo de turbina y $T=5$ es el número de turbinas.\n",
    "\n",
    "Sea $Y$ la matriz aleatoria del mismo tamaño, que corresponde a las variables aleatorias que generan los datos. Entonces se tiene que\n",
    "\n",
    "$$\n",
    "Y_{ij} \\sim \\text{Gamma}(\\phi_{ij}\\mu_{ij}^2, \\phi_{ij}\\mu_{ij}),\n",
    "$$\n",
    "\n",
    "en donde $\\phi_{ij}>0$ y $\\mu_{ij}>0$\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\phi_{ij}&= \\phi_j; \\quad i= 1,\\ldots,N; \\quad j= 1,\\ldots,T\\\\\n",
    "\\ln \\mu_{ij} &= \\mu + \\beta_j; \\quad i= 1,\\ldots,N;\\quad j= 1,\\ldots,T\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Es decir, asumimos un  parámetro de forma $\\phi_j>0$ por cada grupo de turbinas. Adicionalmente se usa la función de enlace $\\ln $, para garantizar que $\\mu_{ij}>0$. Adicionalmente se asume que cada  $\\phi_j>0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por otro lado, existe un problema de identificabilidad, es decir infinitas soluciones, debido a que si $k$ es una constante cualquiera diferente de cero, se tiene que\n",
    "\n",
    "$$\n",
    "\\mu +\\beta_j = (\\mu+k) + (\\beta_j-k)\n",
    "$$\n",
    "\n",
    "En consecuencia es necesario definir una restricción en el modelo. Por ejemplo $\\mu=0$, o $\\beta_j=0$, para algún $j$. Haremos lo siguiente: $\\beta_1=0$.\n",
    "\n",
    "En consecuencia, ahora los parámetros por estimar son $\\phi$, el vector $\\beta = (\\beta_2,\\ldots,\\beta_T)'$ y $\\mu$.\n",
    "\n",
    "Lo que vamos a hacer es declarar digamos $\\beta_f$ como un vector de tamaño $T-1$ y dentro de la sección del modelo hacer lo siguiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue librerias necesarias\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lee los datos\n",
    "path ='./datos/'\n",
    "file ='turbina.dat'\n",
    "turbina = pd.read_csv(path+file, sep='\\s+',header=None) # para Stan\n",
    "datos = np.array(turbina) # para el boxplot\n",
    "turbina.columns = ['a','T1','c','T2','e','T3','g','T4','i','T5']\n",
    "turbina = turbina[['T1','T2','T3','T4','T5']]\n",
    "turbina.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Una primera mirada gráfica de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.DataFrame({\"Tiempo\":datos[:,np.arange(1,10,2)].reshape(5*10),\n",
    "         \"Tipo\":datos[:,np.arange(0,9,2)].reshape(5*10)})\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  plt.figure(figsize=(10,7))\n",
    "sns.boxplot(y=datos[\"Tiempo\"],x=datos[\"Tipo\"] )\n",
    "fig.suptitle('Gráficos boxplot por tipo de motor',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico muestra que en cada grupo de turbinas los datos son en general asimétrico, lo que justifica en principio el modelo Gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación de datos para Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix Y\n",
    "Y = np.array(turbina)\n",
    "N = np.shape(Y)[0]\n",
    "T = np.shape(Y)[1]\n",
    "\n",
    "# data\n",
    "dat ={'Y':Y, 'N':N,'T':T}\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El modelo en Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Magic STAN\n",
    "import pystan\n",
    "%load_ext stanmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stan -f gamma_reg_p1.stan\n",
    "// Gamma log Linear Model for Y\n",
    "\n",
    "data{\n",
    " // number of observations\n",
    " int N;\n",
    " // number of turbines\n",
    " int T;\n",
    " // responses\n",
    " matrix[N,T] Y;\n",
    "}\n",
    "\n",
    "parameters{\n",
    " vector<lower=0>[T]  phi;\n",
    " vector[T-1] beta_f;\n",
    "  real mu;\n",
    "}\n",
    "\n",
    "model{\n",
    " vector[T] beta;\n",
    " matrix[N,T] mu_ij;\n",
    " \n",
    "\n",
    "# priors\n",
    "mu ~ normal(10,10);\n",
    "beta_f ~ normal(0,10);    \n",
    "phi ~ cauchy(0,10);\n",
    "\n",
    "# update beta\n",
    "beta[1] = 0;\n",
    "for (j in 2:(T)){\n",
    "    beta[j] = beta_f[j-1];\n",
    " }\n",
    "\n",
    "# likelihood   \n",
    "for (i in 1:N){\n",
    "    for (j in 1:T){\n",
    "      // means\n",
    "      //mu_ij[i,j] = exp(mu + beta[j]);\n",
    "      //mu_ij[i,j] = (mu_ij[i,j]>27)?27:mu_ij[i,j];\n",
    "      mu_ij[i,j] = (mu + beta[j]);\n",
    "      mu_ij[i,j] = (mu_ij[i,j]<0.01)?0.01:mu_ij[i,j];\n",
    "      //\n",
    "      Y[i,j] ~ gamma(phi[j]*(mu_ij[i,j])^2,phi[j]*mu_ij[i,j]);\n",
    "    }    \n",
    "  }    \n",
    "}\n",
    "\n",
    "generated quantities{\n",
    "  matrix[N,T] residual;\n",
    "  for (i in 1:N){\n",
    "      residual[i,1] = (Y[i,1]-(mu))*sqrt(phi[T]);\n",
    "      for (j in 2:(T)){\n",
    "      residual[i,j] = (Y[i,j]-(mu + beta_f[j-1]))*sqrt(phi[j]);\n",
    "      }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "gamma_model_p1 = pystan.StanModel(file=_stan_model.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Muestreo\n",
    "np.random.seed(127)\n",
    "gamma_model_sample_p1 = gamma_model_p1.sampling(data=dat, iter = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gamma_model_sample_p1.stansummary([\"mu\",\"beta_f\",\"phi\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por hacer..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo para datos binarios 35%\n",
    "\n",
    "La tabla 2 muestra  los datos experimentales sobre la influencia de la razón y del volúmen del aire aspirado en la constricción vascular de la piel de los dedos de la mano, de un experimento reportado por Predigon. \n",
    "\n",
    "\n",
    "\n",
    "La respuesta es dicotómica: ocurrencia (1), y no ocurrecia (0). Se asume para cada observación $Y_i \\sim Ber(\\pi_i)$. El modelo lineal logistico es definido por\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\log \\left(\\frac{\\pi_i}{1-\\pi_i}\\right) = \\beta_1 + \\beta_2 \\log(\\text{volúmen})_i + \\beta_3 \\log(\\text{razón})_i.\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\n",
    "Use Stan para obtener una estimación de los parámetros $\\beta_i, i=1,\\ldots3$. Haga una discusión detallada de los resultados. Incluya los datos, gráficas y estadísticas que considere necesarios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los parámetros del modelo son $\\beta=(\\beta_1,\\beta_2,\\beta_3)'$\n",
    "\n",
    "Los datos son $Y$, volumen y razon y $N$, el número de datos\n",
    "\n",
    "en la sección datos transformados vamos a  hacer las transformaciones requeridas:\n",
    "\n",
    "log_vol = log(volumen)\n",
    "\n",
    "log_razon = log(razon)\n",
    "\n",
    "\n",
    "Para la verosimitud es mejor usar la función *bernoulli_logit* por lo que se puede escribir digamos\n",
    "\n",
    "model {\n",
    "\n",
    "  y ~ bernoulli_logit(beta[1] + beta[2]  $\\times$ log_vol + beta[3]$\\times$log_razon);\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementación en Stan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargue librerias necesarias\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pystan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='./datos/'\n",
    "file ='pregibon.dat'\n",
    "pregibon = pd.read_csv(path+file, sep='\\s+',header=None)\n",
    "pregibon.columns = ['Y','Volume','Razon']\n",
    "pregibon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dictionary\n",
    "datLogit = {'N':pregibon.shape[0], 'K':3,'Y':np.array(pregibon['Y']),\n",
    "          'volume': np.array(pregibon['Volume']), \n",
    "          'razon': np.array(pregibon['Razon'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stan\n",
    "import pystan\n",
    "%load_ext stanmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%stan -f logit_reg_p1.stan\n",
    "// Gamma log Linear Model for Y\n",
    "\n",
    "data{\n",
    " // number of observations\n",
    " int<lower=1> N;\n",
    " // dim regression paramter\n",
    " int<lower=1> K;\n",
    " // Observations\n",
    " int<lower=0> Y[N];\n",
    " // volume\n",
    " vector<lower=0>[N] volume;   \n",
    "  // razon\n",
    " vector<lower=0>[N] razon;     \n",
    " }\n",
    "\n",
    "transformed data{\n",
    "vector[N] log_vol;\n",
    "vector[N] log_razon;   \n",
    "//\n",
    "log_vol = log(volume);\n",
    "log_razon = log(razon);\n",
    "}\n",
    "\n",
    "parameters{\n",
    " vector[K]  beta;\n",
    "}\n",
    "\n",
    "model{\n",
    "// priors\n",
    "beta ~ normal(0,10);\n",
    "// likelihood   \n",
    "for (i in 1:N){\n",
    "   Y[i] ~ bernoulli_logit(beta[1] + beta[2]*log_vol[i] + beta[3]*log_razon[i]);\n",
    "}\n",
    "}\n",
    "\n",
    "\n",
    "generated quantities{\n",
    "  vector[N] residual;\n",
    "  vector[N] prob; \n",
    "  for (i in 1:N){\n",
    "      prob[i] = inv_logit(beta[1] + beta[2]*log_vol[i] + beta[3]*log_razon[i]);\n",
    "      residual[i] = (Y[i]-prob[i])/sqrt(prob[i]*(1-prob[i]));\n",
    "      }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_model_p1 = pystan.StanModel(file=_stan_model.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling\n",
    "logit_model_sample_p1 =logit_model_p1.sampling(data=datLogit, iter = 4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logit_model_sample_p1\n",
    "print(logit_model_sample_p1.stansummary([\"beta\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Por terminar ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
