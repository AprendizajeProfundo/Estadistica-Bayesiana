{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Promedio de Modelos (Model Averaging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2.  Adrian Raftery, [Hypothesis Testing and Model Selection Via Posterior Simulation](https://www.stat.washington.edu/sites/default/files/Other%20Online/test-postsim.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos el escenario en el que el investigador tiene más de un modelo plausible para los datos. Supongamos que $\\mathfrak{M}= \\{M_k, k=1,\\ldots,K\\}$ es el conjunto de modelos plausibles para los datos.\n",
    "\n",
    "\n",
    "Sea $ \\Delta $  la cantidad de interés, por ejemplo un parámetro estructural, una observación futura, la probabilidad de un conjunto, etc.\n",
    "\n",
    "\n",
    "\n",
    "Entonces la probabilidad posterior de  $\\Delta$ dados los datos $D$ se expresa como\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "pr(\\Delta|D) = \\sum_{k=1}^{K} pr(\\Delta|M_k,D)pr(M_k|D).\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Este es un promedio de las probabilidades posteriores de la cantidad $\\Delta$ dados los modelos considerados,  ponderadas por la probabilidad posterior de cada modelo, la cual es dada en cada caso por  $pr(M_k|D)$, en donde por el teorema de Bayes se tiene que\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "pr(M_k|D) = \\frac{pr(D|M_k)pr(M_k)}{\\sum_{k=1}^{K}pr(D|M_k)pr(M_k)}.\n",
    "\\end{equation*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esperanza y Varianza Posteriores de $\\Delta$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La probabilidad $pr(D|M_k)$ es usualmente calculado como sigue.\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "pr(D|M_k) = \\int pr(D|\\theta_k,M_k)pr(\\theta_k|M_k)d\\theta_k,\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "en donde $\\theta_k$ es el parámetro que indexa al modelo $M_k$, y $pr(\\theta_k|M_k)$ es su distribución a priori. En la lección [Cálculo del Factor de Bayes](./cuadernos/MCMC_Bayes_Factor.ipynb) encuentra varios procedimientos prácticos para calcular $pr(D|M_k)$. El más ingenuo es el mostrado en la ecuación anterior y que desde el punto de vista MCMC consiste en calcular una muestra $\\theta_k^{(m)}$ del parámetro para el modelo $k$ a partir de la a priori $pr(\\theta_k|M_k)$, para luego calcular \n",
    "$$\n",
    "\\begin{equation*}\n",
    "pr(D|M_k) \\approx \\frac{1}{S} \\sum_{m=1}^{S}pr(D|\\theta_k^{(m)})\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "Esta aproximación ingenua solamente funciona cuando la apriori es cercana a la verosimilitud.\n",
    "\n",
    "Una alternativa es usar la distribución predictiva posterior.\n",
    "\n",
    "\n",
    "\n",
    "Sea $\\hat{\\Delta}_k= E[\\Delta|D,M_k]$. La esperanza y varianza posterior $\\Delta$ son como como sigue:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "E[\\Delta|D] &= \\sum_{k=1}^{K} \\hat{\\Delta}_k pr(M_k|D)\\\\\n",
    "Var[\\Delta|D] &= \\sum_{k=1}^{K} (Var[\\Delta|D,M_k]+ \\hat{\\Delta}_k^2)pr(M_k|D) - E[\\Delta|D]^2.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
