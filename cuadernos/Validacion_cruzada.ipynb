{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación cruzada\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Mauricio Montenegro Díaz, ammontenegrod@unal.edu.co"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Alvaro Montenegro, [Curso de Estadística Bayesiana](https://github.com/AprendizajeProfundo/Estadistica-Bayesiana), 2020\n",
    "2. Guangyuan Gao, \"Bayesian Claims Reserving Methods in Non-life Insurance with Stan. An Introduction\", Springer, 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción\n",
    "\n",
    "Cuando los datos no son suficientes para ser divididos en dos grupos: entrenamiento y validación, aún es posible usar en lo modelos de regresión las técnicas basadas en  la distribución predictiva como se decribe en esta lección. Primero, recordemos como generar nuevas observaciones con la distribución predictiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predición de  datos no observados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consideremos un modelo bayesiano con parámetros $\\boldsymbol{\\theta}$ y datos continuos $\\mathbf{y}$. Vamos a considerar la posterior $p(\\boldsymbol{\\theta}|y)$ . Entonces generamos nuevos datos como sigue:\n",
    "\n",
    "1. Generamos una muestra $\\boldsymbol{\\theta}^{(1)}, \\ldots, \\boldsymbol{\\theta}^{(n)}$, a partir de la posterior $p(\\boldsymbol{\\theta}|y)$.\n",
    "\n",
    "2. Para cada muestra $\\boldsymbol{\\theta}^{(k)}$ se obtiene una muestra $\\tilde{y}_k$ a partir de valores de un vector concido de variables predictoras, digamos $\\mathbf{z}$,  y $\\boldsymbol{\\theta}^{(k)}$. La muestra se obtiene  de la verosimilitud $p(y|\\boldsymbol{\\theta}^{(k)},\\mathbf{z})$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo. Modelo de Regresión Normal homocedástico $\\mathcal{N}(\\mu_i,\\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si este es el modelo verdadero que produjo los datos, lo que ocurrió es que \n",
    "\n",
    "### Generación de los datos\n",
    "\n",
    "Este es el proceso que teóricamente ocurrió para generar los datos.\n",
    "\n",
    "1. $\\boldsymbol{\\theta}$ fué generado a partir de una distribución (desconocido) $P(\\boldsymbol{\\theta})$. En este ejemplo se tiene que  $\\boldsymbol{\\theta} = (\\alpha,\\boldsymbol{\\beta},\\sigma)'$.\n",
    "\n",
    "2. Cada observación $y_i$ tienen distribución $\\mathcal{N}(\\mu_i,\\sigma^2)$, en donde $\\mu_i = \\alpha + \\mathbf{x}_i'\\boldsymbol{\\beta}$. Así que el dato observado $y_i$ es obtenido como una muestra aleatoria de $\\mathcal{N}(\\mu_i,\\sigma^2)$. \n",
    "\n",
    "\n",
    "### Generación de nuevos datos\n",
    "\n",
    "Nosotros construimos la posterior $p(\\boldsymbol{\\theta}|y)$. Esta es nuestra aproximación de la distribución desconocida $P(\\boldsymbol{\\theta})$. Entonces los datos simulados no observadosse obtienen como sigue.\n",
    "\n",
    "1. Se obtiene una muestra $\\boldsymbol{\\theta}^{(1)}, \\ldots, \\boldsymbol{\\theta}^{(n)}$, a partir de la posterior $p(\\boldsymbol{\\theta}|y)$.  Aquí $\\boldsymbol{\\theta}^{(k)} =(\\alpha^{(k)}, \\boldsymbol{\\beta}^{(k)}, \\sigma^{(k)})'$.\n",
    "\n",
    "2. A partir de cada muestra posterior $(\\alpha^{(k)}, \\boldsymbol{\\beta}^{(k)}, \\sigma^{(k)})'$ se calcula $\\mu_z^{(k)}= \\alpha^{(k)} +\\mathbf{z}'\\boldsymbol{\\beta}^{(k)} $. El dato no observado $\\tilde{y}$ en este caso se obtiene como una muestra de la distribución $\\mathcal{N}(\\mu_z^{(k)},  \\sigma^{(k)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de datos para validación cruzada en modelos de regresión (dejando uno por fuera)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta  técnica es conocida como *loo* del inglés leave one out, o dejar uno por fuera.\n",
    "\n",
    "En este caso, el procedimiento a seguir es el siguiente. Sea $\\mathbf{y}_{-i}$ el conjunto de observaciones excepto $y_i$. Sea $\\mathbf{x}_{i}$  el vector de varables predictoras asociadas a $y_i$. Entonces, una réplica de la observación $y_i$ se obtiene como sigue.\n",
    "\n",
    "1. Se obtiene una muestra $\\boldsymbol{\\theta}^*_{-i}$ de la posterior $p(\\boldsymbol{\\theta}|\\mathbf{y}_{-i})$.\n",
    "2. Se obtiene una réplica de  $y_i$ como una muestra  de la verosimilitud $p(y|\\boldsymbol{\\theta}^*_{-i},\\mathbf{x}_{i})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validación cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que se hace es generar muestras *loo*. Sea  $\\boldsymbol{\\theta}^*_{-i}$ una muestra de la posterior $p(\\boldsymbol{\\theta}|\\mathbf{y}_{-i})$. Definimos $\\mu_{-i}$ como la media aosciada al problema, entonces\n",
    "\n",
    "\n",
    "\n",
    "### Residuales de Pearson estandarizados loo\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "r_{loo}(i) &= \\frac{(y_i-\\mu_{-i})}{\\sigma_{-i}}\\\\\n",
    "T(\\mathbf{y}|\\boldsymbol{\\theta}_{-i}) &= \\sum_{i=1}^n \\frac{(y_i-\\mu_{-i})}{\\sigma_{-i}}\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "###   Discrepancia Deviance \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "T(y_i|\\boldsymbol{\\theta}_{-i}) &= -2 \\log f(y_i|\\boldsymbol{\\theta}_{-i})\\\\ \n",
    "T(\\mathbf{y}|\\boldsymbol{\\theta}_{-i})&=-2 \\sum_{i=1}^n \\log f(y_i|\\boldsymbol{\\theta}_{-i})\n",
    "\\end{align}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección de valores extremos (outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El p-valor Bayesiano puede usarse para detectar valores extremos de los datos, de acuerdo con la distribución del problema.\n",
    "\n",
    "La idea clave es la siguiente. Defina un unmbral, digamos $\\text{umbral} = 2.5$a  partir del cual, si se tiene una variable estandarizada, un valor mayor a este umbral puede considerarse sospechoso de ser un valor extremo.\n",
    "\n",
    "1. En cada paso del algoritmo de muestreo calcule el residual. es decir\n",
    "$$\n",
    "r_i^{(k)} = \\frac{y_i-\\mu_{-i}^{(k)}}{\\sigma_{-i}^{(k)}}\n",
    "$$\n",
    "2. Calcule la estadística $1_{\\{|r_i^{(k)}|>\\text{umbral}\\}}$\n",
    "3. Si se obtienen $m$ muestras, el p-valor Bayesiano es dado por\n",
    "\n",
    "$$\n",
    "p_{\\text{outlier}}(y_i) = \\frac{1}{m}\\sum_{k=1}^m 1_{\\{|r_i^{(k)}|>\\text{umbral}\\}}\n",
    "$$\n",
    " \n",
    "Entonces, valores grandes de $p_{\\text{outlier}}(y_i)$ señalan a $y_i$ como un valor extremo, con una probabilidad dada por este p-valor Bayesiano."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación en Stan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta sección implementamos los conceptos de la lección para los datos stack_loss de lecciones previas. Usaremos el modelo normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datos\n",
    "import numpy as np\n",
    "p = 3\n",
    "N = 1\n",
    "umbral = 2.5\n",
    "y = np.array([43, 37, 37, 28, 18, 18, 19, 20, 15, 14, 14, 13, 11, 12, 8, \n",
    "7, 8, 8, 9, 15, 15])\n",
    "x = np.resize((80, 80, 75, 62, 62, 62, 62, 62, 59, 58, 58, 58, 58, \n",
    "58, 50, 50, 50, 50, 50, 56, 70, 27, 27, 25, 24, 22, 23, 24, 24, \n",
    "23, 18, 18, 17, 18, 19, 18, 18, 19, 19, 20, 20, 20, 89, 88, 90, \n",
    "87, 87, 87, 93, 93, 87, 80, 89, 88, 82, 93, 89, 86, 72, 79, 80, \n",
    "82, 91), (21, 3))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([80, 80, 75])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# leave ou observation i\n",
    "\n",
    "i = 0\n",
    "y_data = np.hstack([y[:i],y[(i+1):]])\n",
    "y_out = y[i]\n",
    "x_data = np.delete(x,i,axis=0)\n",
    "x_out = x[i,:]\n",
    "x_out\n",
    "\n",
    "stacks_data = {'p': p, 'N': N, 'umbral':umbral, \n",
    "               'y': y_data,\n",
    "               'x': x_data,\n",
    "               'y_out',y_out,\n",
    "               'x_out':x_out,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The stanmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext stanmagic\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pystan\n",
    "%load_ext stanmagic\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pylab as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pystan.stanc compiler..\n",
      "-------------------------------------------------------------------------------\n",
      "Model compiled successfully. Output stored in _stan_model object.\n",
      "Type _stan_model in a cell to see a nicely formatted code output in a notebook\n",
      "     ^^^^^^^^^^^\n",
      "Access model compile output properties\n",
      "_stan_model.model_file -> Name of stan_file [normal_stack_loss_reg-p_val.stan]\n",
      "_stan_model.model_name -> Name of stan model [normal_stack_loss_reg-p_val_model]\n",
      "_stan_model.model_code -> Model code [// Linear Model with ....]\n"
     ]
    }
   ],
   "source": [
    "%%stan -f normal_stack_loss_reg-p_val.stan\n",
    "// Linear Model with normal Errors\n",
    "\n",
    "data {\n",
    "  int<lower=0> N;  // number of observations\n",
    "  int<lower=0> p;  // number of explained variables\n",
    "  vector[N] y;     // observations\n",
    "  matrix[N,p] x;   // design matrix\n",
    "  real umbral;     // threshold for outlier detection\n",
    "  real y_out;      // y loo\n",
    "  vector[p] x_out;      // x loo\n",
    "} \n",
    "\n",
    "\n",
    "\n",
    "transformed data {\n",
    "  matrix[N,p] z;\n",
    "  vector[p] mean_x;\n",
    "  vector[p] sd_x;\n",
    "  real y_min;\n",
    "  real y_max;\n",
    "  # order statistics\n",
    "  y_min = min(y);\n",
    "  y_max = max(y);\n",
    "  // standardize the x's \n",
    "  for (j in 1:p) { \n",
    "    mean_x[j] = mean(col(x,j)); \n",
    "    sd_x[j] = sd(col(x,j)); \n",
    "    for (i in 1:N)  \n",
    "      z[i,j] = (x[i,j] - mean_x[j]) / sd_x[j]; \n",
    "  }\n",
    "}\n",
    "\n",
    "parameters {\n",
    "  real beta_0; \n",
    "  vector[p] beta; \n",
    "  real<lower=0> sigma; \n",
    "} \n",
    "\n",
    "transformed parameters {\n",
    "    vector[N] mu;\n",
    "    mu = beta_0 + z*beta;\n",
    "}\n",
    "\n",
    "model {\n",
    "  beta_0 ~ normal(0, 5); \n",
    "  beta   ~ normal(0, 5);\n",
    "  sigma  ~ cauchy(0, 2);\n",
    "  y      ~ normal(mu, sigma);\n",
    "} \n",
    "\n",
    "generated quantities {\n",
    "  vector[N] residual; // Pearson residual\n",
    "  vector[N] outlier;  // test for outlier\n",
    "  vector[N] resi_dev; // residual deviance \n",
    "  vector[N] y_rep;    // replica\n",
    "  real pval_model;    // p-value model\n",
    "  real pval_min;      // p-value minimum\n",
    "  real pval_max;      // p-value maximum\n",
    "  vector[N] Ty;       // Discrepance (data)\n",
    "  vector[N] Ty_rep;   // Discrepance (rep)\n",
    "    \n",
    "  for (i in 1:N){\n",
    "    residual[i] = (y[i] - mu[i]) / sigma;\n",
    "    outlier[i]  = step(residual[i] - umbral);\n",
    "    // cambiar la siguiente línea en cada caso\n",
    "    resi_dev[i] = (y[i] - mu[i])/sigma;\n",
    "    // cambiar la siguientes líneas en cada caso\n",
    "    y_rep[i]  = normal_rng(mu[i],sigma);\n",
    "    Ty[i]     =   normal_lpdf(y[i]|mu[i],sigma);\n",
    "    Ty_rep[i] =   normal_lpdf(y_rep[i]|mu[i],sigma);  \n",
    " }\n",
    " // cambiar la siguiente línea en cada caso\n",
    " pval_model = step(sum(Ty)-sum(Ty_rep));\n",
    " pval_min   = step(y_min - min(y_rep));\n",
    " pval_max   = step(y_max - max(y_rep));\n",
    "}    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html><span><pre> model_file: <b>normal_stack_loss_reg-p_val.stan</b></pre></span><span><pre> model_name: <b>normal_stack_loss_reg-p_val_model</b></pre></span><span><pre><b> model_code :</b></pre></span><style type=\"text/css\">.highlight .hll { background-color: #ffffcc }\n",
       ".highlight  { background: #f8f8f8; }\n",
       ".highlight .c { color: #408080; font-style: italic } /* Comment */\n",
       ".highlight .err { border: 1px solid #FF0000 } /* Error */\n",
       ".highlight .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".highlight .o { color: #666666 } /* Operator */\n",
       ".highlight .ch { color: #408080; font-style: italic } /* Comment.Hashbang */\n",
       ".highlight .cm { color: #408080; font-style: italic } /* Comment.Multiline */\n",
       ".highlight .cp { color: #BC7A00 } /* Comment.Preproc */\n",
       ".highlight .cpf { color: #408080; font-style: italic } /* Comment.PreprocFile */\n",
       ".highlight .c1 { color: #408080; font-style: italic } /* Comment.Single */\n",
       ".highlight .cs { color: #408080; font-style: italic } /* Comment.Special */\n",
       ".highlight .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".highlight .ge { font-style: italic } /* Generic.Emph */\n",
       ".highlight .gr { color: #FF0000 } /* Generic.Error */\n",
       ".highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".highlight .gi { color: #00A000 } /* Generic.Inserted */\n",
       ".highlight .go { color: #888888 } /* Generic.Output */\n",
       ".highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".highlight .gs { font-weight: bold } /* Generic.Strong */\n",
       ".highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".highlight .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".highlight .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".highlight .kt { color: #B00040 } /* Keyword.Type */\n",
       ".highlight .m { color: #666666 } /* Literal.Number */\n",
       ".highlight .s { color: #BA2121 } /* Literal.String */\n",
       ".highlight .na { color: #7D9029 } /* Name.Attribute */\n",
       ".highlight .nb { color: #008000 } /* Name.Builtin */\n",
       ".highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".highlight .no { color: #880000 } /* Name.Constant */\n",
       ".highlight .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".highlight .ni { color: #999999; font-weight: bold } /* Name.Entity */\n",
       ".highlight .ne { color: #D2413A; font-weight: bold } /* Name.Exception */\n",
       ".highlight .nf { color: #0000FF } /* Name.Function */\n",
       ".highlight .nl { color: #A0A000 } /* Name.Label */\n",
       ".highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".highlight .nv { color: #19177C } /* Name.Variable */\n",
       ".highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".highlight .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".highlight .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".highlight .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".highlight .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".highlight .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".highlight .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".highlight .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".highlight .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".highlight .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".highlight .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".highlight .se { color: #BB6622; font-weight: bold } /* Literal.String.Escape */\n",
       ".highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".highlight .si { color: #BB6688; font-weight: bold } /* Literal.String.Interpol */\n",
       ".highlight .sx { color: #008000 } /* Literal.String.Other */\n",
       ".highlight .sr { color: #BB6688 } /* Literal.String.Regex */\n",
       ".highlight .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".highlight .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".highlight .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".highlight .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".highlight .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".highlight .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".highlight .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"c1\">// Linear Model with normal Errors</span>\n",
       "\n",
       "<span class=\"kn\">data</span> <span class=\"p\">{</span>\n",
       "  <span class=\"kt\">int</span><span class=\"o\">&lt;</span><span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"o\">&gt;</span> <span class=\"n\">N</span><span class=\"p\">;</span>  <span class=\"c1\">// number of observations</span>\n",
       "  <span class=\"kt\">int</span><span class=\"o\">&lt;</span><span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"o\">&gt;</span> <span class=\"n\">p</span><span class=\"p\">;</span>  <span class=\"c1\">// number of explained variables</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">y</span><span class=\"p\">;</span>     <span class=\"c1\">// observations</span>\n",
       "  <span class=\"kt\">matrix</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"n\">x</span><span class=\"p\">;</span>   <span class=\"c1\">// design matrix</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">umbral</span><span class=\"p\">;</span>     <span class=\"c1\">// threshold for outlier detection</span>\n",
       "<span class=\"p\">}</span> \n",
       "\n",
       "\n",
       "\n",
       "<span class=\"kn\">transformed data</span> <span class=\"p\">{</span>\n",
       "  <span class=\"kt\">matrix</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">,</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"n\">z</span><span class=\"p\">;</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"n\">mean_x</span><span class=\"p\">;</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"n\">sd_x</span><span class=\"p\">;</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">y_min</span><span class=\"p\">;</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">y_max</span><span class=\"p\">;</span>\n",
       "  <span class=\"c1\"># order statistics</span>\n",
       "  <span class=\"n\">y_min</span> <span class=\"o\">=</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">);</span>\n",
       "  <span class=\"n\">y_max</span> <span class=\"o\">=</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">);</span>\n",
       "  <span class=\"c1\">// standardize the x&#39;s </span>\n",
       "  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">j</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">p</span><span class=\"p\">)</span> <span class=\"p\">{</span> \n",
       "    <span class=\"n\">mean_x</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">mean</span><span class=\"p\">(</span><span class=\"nb\">col</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">));</span> \n",
       "    <span class=\"n\">sd_x</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"nb\">sd</span><span class=\"p\">(</span><span class=\"nb\">col</span><span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">));</span> \n",
       "    <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">N</span><span class=\"p\">)</span>  \n",
       "      <span class=\"n\">z</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">x</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">,</span><span class=\"n\">j</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">mean_x</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">])</span> <span class=\"o\">/</span> <span class=\"n\">sd_x</span><span class=\"p\">[</span><span class=\"n\">j</span><span class=\"p\">];</span> \n",
       "  <span class=\"p\">}</span>\n",
       "<span class=\"p\">}</span>\n",
       "\n",
       "<span class=\"kn\">parameters</span> <span class=\"p\">{</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">beta_0</span><span class=\"p\">;</span> \n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">p</span><span class=\"p\">]</span> <span class=\"n\">beta</span><span class=\"p\">;</span> \n",
       "  <span class=\"kt\">real</span><span class=\"o\">&lt;</span><span class=\"n\">lower</span><span class=\"o\">=</span><span class=\"mi\">0</span><span class=\"o\">&gt;</span> <span class=\"n\">sigma</span><span class=\"p\">;</span> \n",
       "<span class=\"p\">}</span> \n",
       "\n",
       "<span class=\"kn\">transformed parameters</span> <span class=\"p\">{</span>\n",
       "    <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">mu</span><span class=\"p\">;</span>\n",
       "    <span class=\"n\">mu</span> <span class=\"o\">=</span> <span class=\"n\">beta_0</span> <span class=\"o\">+</span> <span class=\"n\">z</span><span class=\"o\">*</span><span class=\"n\">beta</span><span class=\"p\">;</span>\n",
       "<span class=\"p\">}</span>\n",
       "\n",
       "<span class=\"kn\">model</span> <span class=\"p\">{</span>\n",
       "  <span class=\"n\">beta_0</span> <span class=\"o\">~</span> <span class=\"nb\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">);</span> \n",
       "  <span class=\"n\">beta</span>   <span class=\"o\">~</span> <span class=\"nb\">normal</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">5</span><span class=\"p\">);</span>\n",
       "  <span class=\"n\">sigma</span>  <span class=\"o\">~</span> <span class=\"nb\">cauchy</span><span class=\"p\">(</span><span class=\"mi\">0</span><span class=\"p\">,</span> <span class=\"mi\">2</span><span class=\"p\">);</span>\n",
       "  <span class=\"n\">y</span>      <span class=\"o\">~</span> <span class=\"nb\">normal</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">,</span> <span class=\"n\">sigma</span><span class=\"p\">);</span>\n",
       "<span class=\"p\">}</span> \n",
       "\n",
       "<span class=\"kn\">generated quantities</span> <span class=\"p\">{</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">residual</span><span class=\"p\">;</span> <span class=\"c1\">// Pearson residual</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">outlier</span><span class=\"p\">;</span>  <span class=\"c1\">// test for outlier</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">resi_dev</span><span class=\"p\">;</span> <span class=\"c1\">// residual deviance </span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">y_rep</span><span class=\"p\">;</span>    <span class=\"c1\">// replica</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">pval_model</span><span class=\"p\">;</span>    <span class=\"c1\">// p-value model</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">pval_min</span><span class=\"p\">;</span>      <span class=\"c1\">// p-value minimum</span>\n",
       "  <span class=\"kt\">real</span> <span class=\"n\">pval_max</span><span class=\"p\">;</span>      <span class=\"c1\">// p-value maximum</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">Ty</span><span class=\"p\">;</span>       <span class=\"c1\">// Discrepance (data)</span>\n",
       "  <span class=\"kt\">vector</span><span class=\"p\">[</span><span class=\"n\">N</span><span class=\"p\">]</span> <span class=\"n\">Ty_rep</span><span class=\"p\">;</span>   <span class=\"c1\">// Discrepance (rep)</span>\n",
       "    \n",
       "  <span class=\"k\">for</span> <span class=\"p\">(</span><span class=\"n\">i</span> <span class=\"k\">in</span> <span class=\"mi\">1</span><span class=\"o\">:</span><span class=\"n\">N</span><span class=\"p\">){</span>\n",
       "    <span class=\"n\">residual</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">mu</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span> <span class=\"o\">/</span> <span class=\"n\">sigma</span><span class=\"p\">;</span>\n",
       "    <span class=\"n\">outlier</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>  <span class=\"o\">=</span> <span class=\"nb\">step</span><span class=\"p\">(</span><span class=\"n\">residual</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">umbral</span><span class=\"p\">);</span>\n",
       "    <span class=\"c1\">// cambiar la siguiente línea en cada caso</span>\n",
       "    <span class=\"n\">resi_dev</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span> <span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">-</span> <span class=\"n\">mu</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">])</span><span class=\"o\">/</span><span class=\"n\">sigma</span><span class=\"p\">;</span>\n",
       "    <span class=\"c1\">// cambiar la siguientes líneas en cada caso</span>\n",
       "    <span class=\"n\">y_rep</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>  <span class=\"o\">=</span> <span class=\"nb\">normal_rng</span><span class=\"p\">(</span><span class=\"n\">mu</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">sigma</span><span class=\"p\">);</span>\n",
       "    <span class=\"n\">Ty</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span>     <span class=\"o\">=</span>   <span class=\"nb\">normal_lpdf</span><span class=\"p\">(</span><span class=\"n\">y</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]|</span><span class=\"n\">mu</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">sigma</span><span class=\"p\">);</span>\n",
       "    <span class=\"n\">Ty_rep</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]</span> <span class=\"o\">=</span>   <span class=\"nb\">normal_lpdf</span><span class=\"p\">(</span><span class=\"n\">y_rep</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">]|</span><span class=\"n\">mu</span><span class=\"p\">[</span><span class=\"n\">i</span><span class=\"p\">],</span><span class=\"n\">sigma</span><span class=\"p\">);</span>  \n",
       " <span class=\"p\">}</span>\n",
       " <span class=\"c1\">// cambiar la siguiente línea en cada caso</span>\n",
       " <span class=\"n\">pval_model</span> <span class=\"o\">=</span> <span class=\"nb\">step</span><span class=\"p\">(</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">Ty</span><span class=\"p\">)</span><span class=\"o\">-</span><span class=\"nb\">sum</span><span class=\"p\">(</span><span class=\"n\">Ty_rep</span><span class=\"p\">));</span>\n",
       " <span class=\"n\">pval_min</span>   <span class=\"o\">=</span> <span class=\"nb\">step</span><span class=\"p\">(</span><span class=\"n\">y_min</span> <span class=\"o\">-</span> <span class=\"nb\">min</span><span class=\"p\">(</span><span class=\"n\">y_rep</span><span class=\"p\">));</span>\n",
       " <span class=\"n\">pval_max</span>   <span class=\"o\">=</span> <span class=\"nb\">step</span><span class=\"p\">(</span><span class=\"n\">y_max</span> <span class=\"o\">-</span> <span class=\"nb\">max</span><span class=\"p\">(</span><span class=\"n\">y_rep</span><span class=\"p\">));</span>\n",
       "<span class=\"p\">}</span>    \n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "model_file: normal_stack_loss_reg-p_val.stan\n",
       "model_name: normal_stack_loss_reg-p_val_model\n",
       "model_code:\n",
       "// Linear Model with normal Errors\n",
       "\n",
       "data {\n",
       "  int<lower=0> N;  // number of observations\n",
       "  int<lower=0> p;  // number of explained variables\n",
       "  vector[N] y;     // observations\n",
       "  matrix[N,p] x;   // design matrix\n",
       "  real umbral;     // threshold for outlier detection\n",
       "} \n",
       "\n",
       "\n",
       "\n",
       "transformed data {\n",
       "  matrix[N,p] z;\n",
       "  vector[p] mean_x;\n",
       "  vector[p] sd_x;\n",
       "  real y_min;\n",
       "  real y_max;\n",
       "  # order statistics\n",
       "  y_min = min(y);\n",
       "  y_max = max(y);\n",
       "  // standardize the x's \n",
       "  for (j in 1:p) { \n",
       "    mean_x[j] = mean(col(x,j)); \n",
       "    sd_x[j] = sd(col(x,j)); \n",
       "    for (i in 1:N)  \n",
       "      z[i,j] = (x[i,j] - mean_x[j]) / sd_x[j]; \n",
       "  }\n",
       "}\n",
       "\n",
       "parameters {\n",
       "  real beta_0; \n",
       "  vector[p] beta; \n",
       "  real<lower=0> sigma; \n",
       "} \n",
       "\n",
       "transformed parameters {\n",
       "    vector[N] mu;\n",
       "    mu = beta_0 + z*beta;\n",
       "}\n",
       "\n",
       "model {\n",
       "  beta_0 ~ normal(0, 5); \n",
       "  beta   ~ normal(0, 5);\n",
       "  sigma  ~ cauchy(0, 2);\n",
       "  y      ~ normal(mu, sigma);\n",
       "} \n",
       "\n",
       "generated quantities {\n",
       "  vector[N] residual; // Pearson residual\n",
       "  vector[N] outlier;  // test for outlier\n",
       "  vector[N] resi_dev; // residual deviance \n",
       "  vector[N] y_rep;    // replica\n",
       "  real pval_model;    // p-value model\n",
       "  real pval_min;      // p-value minimum\n",
       "  real pval_max;      // p-value maximum\n",
       "  vector[N] Ty;       // Discrepance (data)\n",
       "  vector[N] Ty_rep;   // Discrepance (rep)\n",
       "    \n",
       "  for (i in 1:N){\n",
       "    residual[i] = (y[i] - mu[i]) / sigma;\n",
       "    outlier[i]  = step(residual[i] - umbral);\n",
       "    // cambiar la siguiente línea en cada caso\n",
       "    resi_dev[i] = (y[i] - mu[i])/sigma;\n",
       "    // cambiar la siguientes líneas en cada caso\n",
       "    y_rep[i]  = normal_rng(mu[i],sigma);\n",
       "    Ty[i]     =   normal_lpdf(y[i]|mu[i],sigma);\n",
       "    Ty_rep[i] =   normal_lpdf(y_rep[i]|mu[i],sigma);  \n",
       " }\n",
       " // cambiar la siguiente línea en cada caso\n",
       " pval_model = step(sum(Ty)-sum(Ty_rep));\n",
       " pval_min   = step(y_min - min(y_rep));\n",
       " pval_max   = step(y_max - max(y_rep));\n",
       "}    "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_stan_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_721bdac6da1bb4db402b057e8b2b0723 NOW.\n"
     ]
    }
   ],
   "source": [
    "normal_stack_loss_reg = pystan.StanModel(file=_stan_model.model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:n_eff / iter below 0.001 indicates that the effective sample size has likely been overestimated\n",
      "WARNING:pystan:Rhat above 1.1 or below 0.9 indicates that the chains very likely have not mixed\n"
     ]
    }
   ],
   "source": [
    "# Muestreo\n",
    "np.random.seed(500)\n",
    "normal_stack_loss_reg_sample = normal_stack_loss_reg.sampling(data=stacks_data, iter =4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference for Stan model: anon_model_721bdac6da1bb4db402b057e8b2b0723.\n",
      "4 chains, each with iter=4000; warmup=2000; thin=1; \n",
      "post-warmup draws per chain=2000, total post-warmup draws=8000.\n",
      "\n",
      "               mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
      "beta_0        14.17    0.03   2.45   8.97  12.66   14.3  15.83  18.62   5905    1.0\n",
      "beta[1]        0.92    0.05   3.96  -6.93  -1.78   0.93   3.59   8.64   6056    1.0\n",
      "beta[2]       -0.03    0.05   4.13  -8.21  -2.82  -0.05   2.79   7.88   6261    1.0\n",
      "beta[3]       -0.87    0.05   4.03  -8.89  -3.54  -0.88   1.88    6.9   6113    1.0\n",
      "sigma         11.28    0.03   2.04   8.12   9.84  10.99  12.38  16.17   5116    1.0\n",
      "mu[1]         14.38    0.04   3.26   7.52  12.32   14.5  16.55  20.39   6625    1.0\n",
      "mu[2]          14.2    0.03   2.51   8.96  12.67  14.33  15.91  18.81   5946    1.0\n",
      "mu[3]         14.29    0.03   2.55   8.92  12.72  14.41  16.02  18.93   5783    1.0\n",
      "mu[4]         14.19    0.03   2.46   8.99  12.69  14.31  15.87  18.68   5885    1.0\n",
      "mu[5]         14.43    0.04   2.75    8.6  12.72  14.56  16.31  19.36   5622    1.0\n",
      "mu[6]         14.18    0.03   2.51    8.7  12.62  14.34  15.87   18.7   6083    1.0\n",
      "mu[7]         13.57    0.04   3.35    6.8  11.32  13.64  15.84  20.08   6225    1.0\n",
      "mu[8]          14.2    0.04   3.59   6.74  11.97  14.37   16.6   20.8   7695    1.0\n",
      "mu[9]         14.17    0.04   3.81   6.18  11.84  14.33  16.73  21.26   7948    1.0\n",
      "mu[10]        14.17    0.04   3.76   6.31  11.84  14.31  16.68  21.15   7913    1.0\n",
      "mu[11]        14.16    0.05   4.17   5.46  11.56  14.27  16.96  22.01   8293    1.0\n",
      "mu[12]        14.13    0.05   4.12   5.55  11.56  14.25  16.91  21.81   8273    1.0\n",
      "mu[13]         14.1    0.05    4.1    5.6  11.54  14.22  16.86  21.74   8270    1.0\n",
      "mu[14]        14.13    0.04    4.0   5.82  11.65  14.27  16.82  21.61   8174    1.0\n",
      "mu[15]        14.21    0.04    3.8   6.32  11.75  14.34  16.73  21.25   7835    1.0\n",
      "mu[16]        14.24    0.04   3.67   6.57  11.88  14.39  16.68  21.03   7595    1.0\n",
      "mu[17]        14.43    0.05   4.07   6.01  11.79  14.59  17.17  22.13   7450    1.0\n",
      "mu[18]        13.97    0.04    3.7   6.39  11.61  14.12   16.4  20.99   7372    1.0\n",
      "mu[19]         14.0    0.05    3.9   5.96  11.51  14.15  16.59  21.47   7366    1.0\n",
      "mu[20]        14.46    0.04   3.69   7.04  12.06  14.56  16.99   21.4   6748    1.0\n",
      "mu[21]        13.89    0.04   3.67   6.45  11.52  14.03  16.36  20.85   7533    1.0\n",
      "residual[1]     2.6  5.3e-3   0.45   1.75    2.3    2.6   2.89   3.52   7255    1.0\n",
      "residual[2]    2.07  3.9e-3   0.34   1.43   1.84   2.06   2.29   2.76   7508    1.0\n",
      "residual[3]    2.06  4.0e-3   0.34   1.42   1.83   2.05   2.28   2.74   7185    1.0\n",
      "residual[4]    1.25  2.5e-3   0.24   0.79   1.09   1.24    1.4   1.73   8651    1.0\n",
      "residual[5]    0.31  2.7e-3   0.23  -0.14   0.16   0.31   0.46   0.75   6939    1.0\n",
      "residual[6]    0.33  2.3e-3    0.2  -0.07    0.2   0.34   0.47   0.73   8107    1.0\n",
      "residual[7]    0.48  3.6e-3    0.3   -0.1   0.29   0.48   0.68   1.08   6672    1.0\n",
      "residual[8]    0.51  3.1e-3    0.3  -0.07   0.31   0.52   0.71   1.11   9284    1.0\n",
      "residual[9]    0.06  3.6e-3   0.33  -0.59  -0.16   0.06   0.28    0.7   8637    1.0\n",
      "residual[10]  -0.03  3.6e-3   0.33  -0.68  -0.25  -0.03   0.19    0.6   8462    1.0\n",
      "residual[11]  -0.03  3.9e-3   0.37  -0.75  -0.28  -0.03   0.21   0.68   8720    1.0\n",
      "residual[12]  -0.12  3.9e-3   0.36  -0.84  -0.36  -0.11   0.13   0.59   8562    1.0\n",
      "residual[13]   -0.3  4.1e-3   0.37  -1.03  -0.54  -0.29  -0.05   0.42   8246    1.0\n",
      "residual[14]  -0.21  3.9e-3   0.36  -0.92  -0.45  -0.21   0.03   0.48   8318    1.0\n",
      "residual[15]  -0.58  4.3e-3   0.37  -1.33  -0.83  -0.58  -0.33   0.14   7312    1.0\n",
      "residual[16]  -0.68  4.4e-3   0.37  -1.42  -0.92  -0.68  -0.42   0.03   7070    1.0\n",
      "residual[17]   -0.6  4.7e-3    0.4  -1.41  -0.87   -0.6  -0.33   0.16   7187    1.0\n",
      "residual[18]  -0.56  4.2e-3   0.36  -1.29   -0.8  -0.56  -0.31   0.13   7224    1.0\n",
      "residual[19]  -0.47  4.3e-3   0.37  -1.23  -0.72  -0.47  -0.22   0.24   7330    1.0\n",
      "residual[20]   0.03  3.9e-3   0.33  -0.62  -0.19   0.04   0.26   0.64   7180    1.0\n",
      "residual[21]   0.09  3.6e-3   0.32  -0.55  -0.12   0.09    0.3    0.7   8006    1.0\n",
      "outlier[1]      1.0  7.6e-4   0.06    1.0    1.0    1.0    1.0    1.0   6884    1.0\n",
      "outlier[2]     0.96  2.7e-3    0.2    0.0    1.0    1.0    1.0    1.0   5467    1.0\n",
      "outlier[3]     0.96  2.8e-3   0.21    0.0    1.0    1.0    1.0    1.0   5364    1.0\n",
      "outlier[4]     0.14  4.3e-3   0.35    0.0    0.0    0.0    0.0    1.0   6613    1.0\n",
      "outlier[5]      0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[6]      0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[7]   6.2e-4     nan   0.02    0.0    0.0    0.0    0.0    0.0    nan    1.0\n",
      "outlier[8]   6.2e-4     nan   0.02    0.0    0.0    0.0    0.0    0.0    nan    1.0\n",
      "outlier[9]      0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[10]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[11]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[12]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[13]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[14]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[15]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[16]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[17]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[18]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[19]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[20]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "outlier[21]     0.0     nan    0.0    0.0    0.0    0.0    0.0    0.0    nan    nan\n",
      "resi_dev[1]     2.6  5.3e-3   0.45   1.75    2.3    2.6   2.89   3.52   7255    1.0\n",
      "resi_dev[2]    2.07  3.9e-3   0.34   1.43   1.84   2.06   2.29   2.76   7508    1.0\n",
      "resi_dev[3]    2.06  4.0e-3   0.34   1.42   1.83   2.05   2.28   2.74   7185    1.0\n",
      "resi_dev[4]    1.25  2.5e-3   0.24   0.79   1.09   1.24    1.4   1.73   8651    1.0\n",
      "resi_dev[5]    0.31  2.7e-3   0.23  -0.14   0.16   0.31   0.46   0.75   6939    1.0\n",
      "resi_dev[6]    0.33  2.3e-3    0.2  -0.07    0.2   0.34   0.47   0.73   8107    1.0\n",
      "resi_dev[7]    0.48  3.6e-3    0.3   -0.1   0.29   0.48   0.68   1.08   6672    1.0\n",
      "resi_dev[8]    0.51  3.1e-3    0.3  -0.07   0.31   0.52   0.71   1.11   9284    1.0\n",
      "resi_dev[9]    0.06  3.6e-3   0.33  -0.59  -0.16   0.06   0.28    0.7   8637    1.0\n",
      "resi_dev[10]  -0.03  3.6e-3   0.33  -0.68  -0.25  -0.03   0.19    0.6   8462    1.0\n",
      "resi_dev[11]  -0.03  3.9e-3   0.37  -0.75  -0.28  -0.03   0.21   0.68   8720    1.0\n",
      "resi_dev[12]  -0.12  3.9e-3   0.36  -0.84  -0.36  -0.11   0.13   0.59   8562    1.0\n",
      "resi_dev[13]   -0.3  4.1e-3   0.37  -1.03  -0.54  -0.29  -0.05   0.42   8246    1.0\n",
      "resi_dev[14]  -0.21  3.9e-3   0.36  -0.92  -0.45  -0.21   0.03   0.48   8318    1.0\n",
      "resi_dev[15]  -0.58  4.3e-3   0.37  -1.33  -0.83  -0.58  -0.33   0.14   7312    1.0\n",
      "resi_dev[16]  -0.68  4.4e-3   0.37  -1.42  -0.92  -0.68  -0.42   0.03   7070    1.0\n",
      "resi_dev[17]   -0.6  4.7e-3    0.4  -1.41  -0.87   -0.6  -0.33   0.16   7187    1.0\n",
      "resi_dev[18]  -0.56  4.2e-3   0.36  -1.29   -0.8  -0.56  -0.31   0.13   7224    1.0\n",
      "resi_dev[19]  -0.47  4.3e-3   0.37  -1.23  -0.72  -0.47  -0.22   0.24   7330    1.0\n",
      "resi_dev[20]   0.03  3.9e-3   0.33  -0.62  -0.19   0.04   0.26   0.64   7180    1.0\n",
      "resi_dev[21]   0.09  3.6e-3   0.32  -0.55  -0.12   0.09    0.3    0.7   8006    1.0\n",
      "y_rep[1]      14.42    0.13  11.75  -9.24   6.81  14.52   22.3  37.37   7863    1.0\n",
      "y_rep[2]      14.28    0.13   11.6  -9.01   6.79  14.36  22.04  36.73   7571    1.0\n",
      "y_rep[3]      14.47    0.13  11.72  -9.15   6.83   14.7  22.26   36.8   7722    1.0\n",
      "y_rep[4]      14.01    0.13  11.85 -10.22   6.58  14.25  21.75   37.0   8514    1.0\n",
      "y_rep[5]      14.48    0.13  11.74  -9.14   6.78  14.67  22.22  37.18   7885    1.0\n",
      "y_rep[6]      13.99    0.13  11.73  -9.97   6.48  14.21  21.77  36.78   7918    1.0\n",
      "y_rep[7]      13.37    0.13  11.97 -10.55   5.53  13.47  21.44  36.63   7996    1.0\n",
      "y_rep[8]       14.2    0.14  11.96 -10.28   6.52  14.41   21.9  37.27   7819    1.0\n",
      "y_rep[9]      14.19    0.14  12.12  -10.8   6.45  14.52  22.28  37.24   7937    1.0\n",
      "y_rep[10]     14.17    0.14   12.3 -10.84   6.29  14.15  22.31  37.97   7924    1.0\n",
      "y_rep[11]     14.03    0.13  12.37 -10.82   6.05  14.31  22.09  38.08   8588    1.0\n",
      "y_rep[12]     14.25    0.14  12.32  -10.7   6.35  14.41  22.28  38.34   8084    1.0\n",
      "y_rep[13]     14.08    0.14   12.3 -11.15   6.37  14.08  22.13   38.3   7826    1.0\n",
      "y_rep[14]      14.2    0.14   12.1 -10.56   6.58  14.22  22.05  37.46   8039    1.0\n",
      "y_rep[15]     14.15    0.14  12.12 -10.49   6.52  14.31  22.05  37.89   7079    1.0\n",
      "y_rep[16]     14.02    0.13  12.02 -10.54   6.42  14.19  21.94  37.77   8322    1.0\n",
      "y_rep[17]      14.5    0.14  12.08  -9.78   6.57  14.86  22.48  37.88   7440    1.0\n",
      "y_rep[18]     14.01    0.14  12.18 -10.01   6.22  14.12   21.9  38.28   7615    1.0\n",
      "y_rep[19]     14.07    0.14  12.02  -10.3   6.35  14.25  21.95  37.57   7334    1.0\n",
      "y_rep[20]     14.54    0.15  12.16   -9.6   6.72  14.66  22.66  37.86   6991    1.0\n",
      "y_rep[21]     13.83    0.14   12.1 -10.62   5.98  13.92  21.69  37.57   7767    1.0\n",
      "pval_model     0.47  5.6e-3    0.5    0.0    0.0    0.0    1.0    1.0   7953    1.0\n",
      "pval_min       0.99  1.0e-3   0.09    1.0    1.0    1.0    1.0    1.0   7699    1.0\n",
      "pval_max       0.84  4.2e-3   0.36    0.0    1.0    1.0    1.0    1.0   7428    1.0\n",
      "Ty[1]         -6.81    0.01   1.06  -9.26  -7.42  -6.68  -6.06  -5.13   7760    1.0\n",
      "Ty[2]         -5.52  6.4e-3   0.59  -6.88  -5.86  -5.45   -5.1  -4.59   8441    1.0\n",
      "Ty[3]         -5.51  6.4e-3   0.58  -6.83  -5.84  -5.43  -5.09  -4.58   8227    1.0\n",
      "Ty[4]         -4.13  2.9e-3   0.25   -4.7  -4.29  -4.12  -3.95  -3.68   7789    1.0\n",
      "Ty[5]          -3.4  2.8e-3    0.2  -3.83  -3.52  -3.38  -3.26  -3.05   4886    1.0\n",
      "Ty[6]          -3.4  2.8e-3    0.2  -3.82  -3.53  -3.39  -3.26  -3.06   4932    1.0\n",
      "Ty[7]         -3.49  3.0e-3   0.22  -3.97  -3.63  -3.47  -3.33   -3.1   5375    1.0\n",
      "Ty[8]          -3.5  3.3e-3   0.24  -4.04  -3.65  -3.48  -3.34   -3.1   5436    1.0\n",
      "Ty[9]         -3.38  3.0e-3   0.19  -3.81   -3.5  -3.36  -3.25  -3.05   4294    1.0\n",
      "Ty[10]        -3.38  2.9e-3   0.19  -3.78  -3.49  -3.37  -3.25  -3.05   4235    1.0\n",
      "Ty[11]        -3.39  3.1e-3    0.2  -3.82  -3.51  -3.38  -3.26  -3.06   4103    1.0\n",
      "Ty[12]         -3.4  2.9e-3   0.19  -3.82  -3.51  -3.38  -3.27  -3.07   4339    1.0\n",
      "Ty[13]        -3.44  2.8e-3    0.2  -3.89  -3.55  -3.43   -3.3   -3.1   5095    1.0\n",
      "Ty[14]        -3.41  2.8e-3   0.19  -3.83  -3.52   -3.4  -3.28  -3.08   4713    1.0\n",
      "Ty[15]        -3.56  2.7e-3   0.23  -4.09  -3.69  -3.54  -3.41   -3.2   7303    1.0\n",
      "Ty[16]        -3.62  2.7e-3   0.24  -4.19  -3.75  -3.59  -3.46  -3.25   7834    1.0\n",
      "Ty[17]        -3.59  3.0e-3   0.25  -4.21  -3.71  -3.55  -3.42   -3.2   7225    1.0\n",
      "Ty[18]        -3.55  2.7e-3   0.22  -4.06  -3.67  -3.52   -3.4  -3.19   6585    1.0\n",
      "Ty[19]        -3.51  2.8e-3   0.22  -3.99  -3.63  -3.48  -3.36  -3.15   6059    1.0\n",
      "Ty[20]        -3.38  2.6e-3   0.19  -3.78  -3.49  -3.36  -3.25  -3.05   4927    1.0\n",
      "Ty[21]        -3.38  2.8e-3   0.19  -3.79   -3.5  -3.37  -3.25  -3.04   4792    1.0\n",
      "Ty_rep[1]     -3.82  8.2e-3   0.72  -5.82  -4.01  -3.61  -3.38  -3.11   7662    1.0\n",
      "Ty_rep[2]     -3.81  8.0e-3   0.72  -5.82   -4.0  -3.59  -3.37   -3.1   8032    1.0\n",
      "Ty_rep[3]     -3.83  8.0e-3   0.71  -5.86  -4.03  -3.61  -3.38   -3.1   7947    1.0\n",
      "Ty_rep[4]     -3.83  8.3e-3   0.74  -5.93   -4.0   -3.6  -3.38  -3.11   7879    1.0\n",
      "Ty_rep[5]     -3.83  8.0e-3   0.71  -5.83  -4.02  -3.61  -3.38  -3.11   7856    1.0\n",
      "Ty_rep[6]     -3.82  8.3e-3   0.73   -5.9   -4.0   -3.6  -3.38  -3.11   7804    1.0\n",
      "Ty_rep[7]     -3.83  8.8e-3   0.72  -5.89  -4.05  -3.62  -3.38  -3.11   6850    1.0\n",
      "Ty_rep[8]     -3.82  8.4e-3   0.73  -5.85  -4.01   -3.6  -3.38  -3.11   7601    1.0\n",
      "Ty_rep[9]     -3.82  8.3e-3   0.71  -5.85  -4.02   -3.6  -3.38  -3.11   7363    1.0\n",
      "Ty_rep[10]    -3.84  8.5e-3   0.75  -6.02  -4.03  -3.61  -3.38  -3.11   7883    1.0\n",
      "Ty_rep[11]    -3.84  8.4e-3   0.76  -5.97  -4.03   -3.6  -3.38  -3.11   8045    1.0\n",
      "Ty_rep[12]    -3.83  8.5e-3   0.74  -5.93  -4.02  -3.61  -3.38  -3.11   7542    1.0\n",
      "Ty_rep[13]    -3.84  8.3e-3   0.74  -5.88  -4.03   -3.6  -3.38  -3.11   7965    1.0\n",
      "Ty_rep[14]    -3.82  8.4e-3   0.74  -5.88   -4.0  -3.59  -3.38  -3.11   7686    1.0\n",
      "Ty_rep[15]    -3.82  8.1e-3   0.71  -5.86  -4.02   -3.6  -3.38  -3.11   7672    1.0\n",
      "Ty_rep[16]    -3.83  8.5e-3   0.74  -5.87  -4.01   -3.6  -3.38  -3.11   7684    1.0\n",
      "Ty_rep[17]    -3.82  7.9e-3    0.7  -5.78  -4.02  -3.61  -3.38   -3.1   7932    1.0\n",
      "Ty_rep[18]    -3.83  8.3e-3   0.74  -5.95  -4.03  -3.61  -3.38   -3.1   7964    1.0\n",
      "Ty_rep[19]    -3.82  8.2e-3   0.73  -5.78   -4.0   -3.6  -3.38   -3.1   7924    1.0\n",
      "Ty_rep[20]    -3.83  8.0e-3   0.71   -5.8  -4.03  -3.61  -3.38  -3.11   7925    1.0\n",
      "Ty_rep[21]    -3.83  8.3e-3   0.74  -5.94  -4.01   -3.6  -3.38  -3.11   7848    1.0\n",
      "lp__         -67.66    0.03   1.68 -71.93 -68.53 -67.32 -66.44 -65.48   3166    1.0\n",
      "\n",
      "Samples were drawn using NUTS at Tue May 26 15:22:03 2020.\n",
      "For each parameter, n_eff is a crude measure of effective sample size,\n",
      "and Rhat is the potential scale reduction factor on split chains (at \n",
      "convergence, Rhat=1).\n"
     ]
    }
   ],
   "source": [
    "print(normal_stack_loss_reg_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_stack_loss_reg_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Repita el ejercicio para las distribuciones Laplace y $t_4$\n",
    "2. ¿Cuáles datos se reportarían como outlier? Distuca su respuesta.\n",
    "3. ¿Cuál model es aparentemente mejor?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
